{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramaastra/sekarya-machine-learning/blob/main/sekarya_model_with_kfold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II3igpiWR7Tr",
        "outputId": "a75fbd56-053c-42f6-a2d4-6736a5d7c94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/New-Sekarya-Dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXmbYIQgBKUy",
        "outputId": "de2f81c8-807b-43dd-c436-75941e43429b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'drive/MyDrive/New-Sekarya-Dataset/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import img_to_array, load_img\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "ABmtGn8wR_zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = f'drive/MyDrive/New-Sekarya-Dataset/'\n",
        "os.listdir(dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isu749ilFFE8",
        "outputId": "379c9735-40ac-4047-96e9-60d234856cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCChtkojFb9H",
        "outputId": "b274b78a-b776-459f-9a9a-73b33d74f3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ai_generated', 'non_ai_generated']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_fake_dir = os.path.join(train_dir, 'ai_generated')\n",
        "train_real_dir = os.path.join(train_dir, 'non_ai_generated')\n",
        "test_dir = os.path.join(dataset_dir, 'test')\n",
        "\n",
        "print(f'There are {len(os.listdir(train_fake_dir))} images of fake images for training.\\n')\n",
        "print(f'There are {len(os.listdir(train_real_dir))} images of real images for training.\\n')\n",
        "print(f'There are {len(os.listdir(test_dir))} images for testing.\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Th0Hlheazc",
        "outputId": "795897ad-44a5-4396-dd73-79f1d7ed0b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 331 images of fake images for training.\n",
            "\n",
            "There are 2501 images of real images for training.\n",
            "\n",
            "There are 2192 images for testing.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "class_labels = os.listdir(train_dir)\n",
        "for class_label in class_labels:\n",
        "  class_data_path = os.path.join(train_dir, class_label)\n",
        "  for filename in os.listdir(class_data_path):\n",
        "    file_path = os.path.join(class_data_path, filename)\n",
        "    images.append(file_path)\n",
        "    labels.append(class_label)\n",
        "\n",
        "print(f'There are {len(images)} images will be splitted with K-Fold.\\n')"
      ],
      "metadata": {
        "id": "Gnpr0ziXe5vZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e62fd0-e8fc-4c95-c381-d63f238f8e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2832 images will be splitted with K-Fold.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                loss=BinaryCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "4P6CV_KXJVvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=5,\n",
        "                               mode='auto',\n",
        "                               restore_best_weights=True)"
      ],
      "metadata": {
        "id": "8_jvBHYwPDMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 6\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=128)"
      ],
      "metadata": {
        "id": "h0xHmNypTQ8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "losses = []\n",
        "\n",
        "for k, (train_indices, val_indices) in enumerate(kfold.split(images, labels)):\n",
        "  print('==============================================================')\n",
        "  print(f'[Processing Fold-{k}...]')\n",
        "\n",
        "  # Creating lists for images and labels based on the train and val indices\n",
        "  x_train = [images[i] for i in train_indices]\n",
        "  y_train = [labels[i] for i in train_indices]\n",
        "  x_val = [images[i] for i in val_indices]\n",
        "  y_val = [labels[i] for i in val_indices]\n",
        "\n",
        "  # Creating dataframe for each train and val list\n",
        "  train_df = pd.DataFrame({\n",
        "    'image': x_train,\n",
        "    'label': y_train\n",
        "  })\n",
        "  val_df = pd.DataFrame({\n",
        "    'image': x_val,\n",
        "    'label': y_val\n",
        "  })\n",
        "\n",
        "  # Creating the image generator to process the images\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255.0)\n",
        "  val_datagen = ImageDataGenerator(rescale=1./255.0)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_dataframe(train_df,\n",
        "                                                      x_col='image',\n",
        "                                                      y_col='label',\n",
        "                                                      target_size=(224, 224),\n",
        "                                                      batch_size=64,\n",
        "                                                      color_mode='rgb',\n",
        "                                                      class_mode='binary')\n",
        "\n",
        "  val_generator = val_datagen.flow_from_dataframe(val_df,\n",
        "                                                  x_col='image',\n",
        "                                                  y_col='label',\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=64,\n",
        "                                                  color_mode='rgb',\n",
        "                                                  class_mode='binary')\n",
        "\n",
        "  # Train the model for this fold\n",
        "  model = cnn_model()\n",
        "  history = model.fit(train_generator,\n",
        "                      epochs=10,\n",
        "                      validation_data=val_generator,\n",
        "                      verbose=1,\n",
        "                      callbacks=[early_stopping])\n",
        "\n",
        "  # Evaluate the model on the validation set\n",
        "  _, accuracy = model.evaluate(val_generator)\n",
        "  print(f'\\nValidation Accuracy for Fold-{k}: {accuracy}')\n",
        "\n",
        "  # Save the model into directory\n",
        "  model.save(f'/content/models/model-{k}.h5')\n",
        "\n",
        "  # Store the accuracy and loss for this fold\n",
        "  accuracies.append(accuracy)\n",
        "  losses.append(history.history['loss'][-1])\n",
        "\n",
        "  print('==============================================================\\n\\n')\n",
        "\n",
        "# Calculate average accuracy and loss across folds\n",
        "average_accuracy = sum(accuracies) / num_folds\n",
        "average_loss = sum(losses) / num_folds\n",
        "\n",
        "print(f'Average accuracy: {average_accuracy:.4f}')\n",
        "print(f'Average loss: {average_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpoetgWKjzz2",
        "outputId": "7bd5ed70-d8f9-4317-e23e-f0f68c4a1186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================================\n",
            "[Processing Fold-0...]\n",
            "Found 2360 validated image filenames belonging to 2 classes.\n",
            "Found 472 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "37/37 [==============================] - 1027s 28s/step - loss: 0.3906 - accuracy: 0.8725 - val_loss: 0.3602 - val_accuracy: 0.8814\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 74s 2s/step - loss: 0.3385 - accuracy: 0.8835 - val_loss: 0.3620 - val_accuracy: 0.8814\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 73s 2s/step - loss: 0.3193 - accuracy: 0.8835 - val_loss: 0.3575 - val_accuracy: 0.8814\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 78s 2s/step - loss: 0.2920 - accuracy: 0.8856 - val_loss: 0.3426 - val_accuracy: 0.8729\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 76s 2s/step - loss: 0.2691 - accuracy: 0.8928 - val_loss: 0.3291 - val_accuracy: 0.8792\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 74s 2s/step - loss: 0.2453 - accuracy: 0.8983 - val_loss: 0.3364 - val_accuracy: 0.8771\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 82s 2s/step - loss: 0.2337 - accuracy: 0.9038 - val_loss: 0.3343 - val_accuracy: 0.8686\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 75s 2s/step - loss: 0.1875 - accuracy: 0.9288 - val_loss: 0.3162 - val_accuracy: 0.8771\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 75s 2s/step - loss: 0.1685 - accuracy: 0.9394 - val_loss: 0.3050 - val_accuracy: 0.8792\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 74s 2s/step - loss: 0.1394 - accuracy: 0.9513 - val_loss: 0.3085 - val_accuracy: 0.8814\n",
            "8/8 [==============================] - 13s 1s/step - loss: 0.3085 - accuracy: 0.8814\n",
            "\n",
            "Validation Accuracy for Fold-0: 0.8813559412956238\n",
            "==============================================================\n",
            "\n",
            "\n",
            "==============================================================\n",
            "[Processing Fold-1...]\n",
            "Found 2360 validated image filenames belonging to 2 classes.\n",
            "Found 472 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "37/37 [==============================] - 76s 2s/step - loss: 0.3726 - accuracy: 0.8653 - val_loss: 0.3556 - val_accuracy: 0.8835\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 80s 2s/step - loss: 0.3437 - accuracy: 0.8831 - val_loss: 0.3526 - val_accuracy: 0.8835\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 83s 2s/step - loss: 0.3266 - accuracy: 0.8831 - val_loss: 0.3487 - val_accuracy: 0.8814\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 78s 2s/step - loss: 0.3068 - accuracy: 0.8831 - val_loss: 0.3363 - val_accuracy: 0.8835\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 87s 2s/step - loss: 0.2909 - accuracy: 0.8831 - val_loss: 0.3171 - val_accuracy: 0.8814\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 86s 2s/step - loss: 0.2620 - accuracy: 0.8869 - val_loss: 0.3024 - val_accuracy: 0.8814\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 84s 2s/step - loss: 0.2346 - accuracy: 0.9004 - val_loss: 0.3036 - val_accuracy: 0.8856\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 83s 2s/step - loss: 0.2133 - accuracy: 0.9119 - val_loss: 0.2992 - val_accuracy: 0.8856\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 75s 2s/step - loss: 0.1881 - accuracy: 0.9233 - val_loss: 0.3006 - val_accuracy: 0.8898\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 84s 2s/step - loss: 0.1780 - accuracy: 0.9309 - val_loss: 0.2797 - val_accuracy: 0.8792\n",
            "8/8 [==============================] - 14s 2s/step - loss: 0.2797 - accuracy: 0.8792\n",
            "\n",
            "Validation Accuracy for Fold-1: 0.8792372941970825\n",
            "==============================================================\n",
            "\n",
            "\n",
            "==============================================================\n",
            "[Processing Fold-2...]\n",
            "Found 2360 validated image filenames belonging to 2 classes.\n",
            "Found 472 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "37/37 [==============================] - 76s 2s/step - loss: 0.3775 - accuracy: 0.8674 - val_loss: 0.3426 - val_accuracy: 0.8835\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 77s 2s/step - loss: 0.3417 - accuracy: 0.8831 - val_loss: 0.3490 - val_accuracy: 0.8835\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 72s 2s/step - loss: 0.3479 - accuracy: 0.8835 - val_loss: 0.3298 - val_accuracy: 0.8835\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 79s 2s/step - loss: 0.3238 - accuracy: 0.8831 - val_loss: 0.3177 - val_accuracy: 0.8835\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 77s 2s/step - loss: 0.2969 - accuracy: 0.8831 - val_loss: 0.3125 - val_accuracy: 0.8835\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 75s 2s/step - loss: 0.2755 - accuracy: 0.8890 - val_loss: 0.3068 - val_accuracy: 0.8835\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 73s 2s/step - loss: 0.2553 - accuracy: 0.8966 - val_loss: 0.2965 - val_accuracy: 0.8814\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 76s 2s/step - loss: 0.2339 - accuracy: 0.9000 - val_loss: 0.3021 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 80s 2s/step - loss: 0.2186 - accuracy: 0.9106 - val_loss: 0.3321 - val_accuracy: 0.8835\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 81s 2s/step - loss: 0.2008 - accuracy: 0.9153 - val_loss: 0.2885 - val_accuracy: 0.8771\n",
            "8/8 [==============================] - 14s 2s/step - loss: 0.2885 - accuracy: 0.8771\n",
            "\n",
            "Validation Accuracy for Fold-2: 0.8771186470985413\n",
            "==============================================================\n",
            "\n",
            "\n",
            "==============================================================\n",
            "[Processing Fold-3...]\n",
            "Found 2360 validated image filenames belonging to 2 classes.\n",
            "Found 472 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "37/37 [==============================] - 75s 2s/step - loss: 0.3838 - accuracy: 0.8636 - val_loss: 0.3577 - val_accuracy: 0.8835\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 84s 2s/step - loss: 0.3504 - accuracy: 0.8831 - val_loss: 0.3503 - val_accuracy: 0.8835\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 74s 2s/step - loss: 0.3376 - accuracy: 0.8831 - val_loss: 0.3412 - val_accuracy: 0.8835\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 77s 2s/step - loss: 0.3218 - accuracy: 0.8831 - val_loss: 0.3340 - val_accuracy: 0.8835\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 76s 2s/step - loss: 0.2996 - accuracy: 0.8831 - val_loss: 0.3203 - val_accuracy: 0.8835\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 75s 2s/step - loss: 0.2860 - accuracy: 0.8831 - val_loss: 0.3188 - val_accuracy: 0.8835\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 76s 2s/step - loss: 0.2591 - accuracy: 0.8873 - val_loss: 0.3097 - val_accuracy: 0.8877\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 75s 2s/step - loss: 0.2367 - accuracy: 0.9047 - val_loss: 0.3346 - val_accuracy: 0.8835\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 71s 2s/step - loss: 0.2119 - accuracy: 0.9140 - val_loss: 0.3070 - val_accuracy: 0.8665\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 74s 2s/step - loss: 0.1897 - accuracy: 0.9246 - val_loss: 0.3006 - val_accuracy: 0.8814\n",
            "8/8 [==============================] - 12s 1s/step - loss: 0.3006 - accuracy: 0.8814\n",
            "\n",
            "Validation Accuracy for Fold-3: 0.8813559412956238\n",
            "==============================================================\n",
            "\n",
            "\n",
            "==============================================================\n",
            "[Processing Fold-4...]\n",
            "Found 2360 validated image filenames belonging to 2 classes.\n",
            "Found 472 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "37/37 [==============================] - 76s 2s/step - loss: 0.3758 - accuracy: 0.8831 - val_loss: 0.3513 - val_accuracy: 0.8835\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 75s 2s/step - loss: 0.3465 - accuracy: 0.8831 - val_loss: 0.3380 - val_accuracy: 0.8835\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 75s 2s/step - loss: 0.3320 - accuracy: 0.8831 - val_loss: 0.3519 - val_accuracy: 0.8835\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 73s 2s/step - loss: 0.3109 - accuracy: 0.8831 - val_loss: 0.3126 - val_accuracy: 0.8835\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 81s 2s/step - loss: 0.2844 - accuracy: 0.8831 - val_loss: 0.3039 - val_accuracy: 0.8835\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 76s 2s/step - loss: 0.2563 - accuracy: 0.8860 - val_loss: 0.2952 - val_accuracy: 0.8835\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 70s 2s/step - loss: 0.2420 - accuracy: 0.8962 - val_loss: 0.2864 - val_accuracy: 0.8856\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 83s 2s/step - loss: 0.2282 - accuracy: 0.9034 - val_loss: 0.2914 - val_accuracy: 0.8856\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 71s 2s/step - loss: 0.1905 - accuracy: 0.9178 - val_loss: 0.2900 - val_accuracy: 0.8856\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 72s 2s/step - loss: 0.1722 - accuracy: 0.9326 - val_loss: 0.2852 - val_accuracy: 0.8877\n",
            "8/8 [==============================] - 13s 2s/step - loss: 0.2852 - accuracy: 0.8877\n",
            "\n",
            "Validation Accuracy for Fold-4: 0.8877118825912476\n",
            "==============================================================\n",
            "\n",
            "\n",
            "==============================================================\n",
            "[Processing Fold-5...]\n",
            "Found 2360 validated image filenames belonging to 2 classes.\n",
            "Found 472 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "37/37 [==============================] - 73s 2s/step - loss: 0.3719 - accuracy: 0.8733 - val_loss: 0.3492 - val_accuracy: 0.8835\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 77s 2s/step - loss: 0.3447 - accuracy: 0.8831 - val_loss: 0.3466 - val_accuracy: 0.8835\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 74s 2s/step - loss: 0.3312 - accuracy: 0.8831 - val_loss: 0.3498 - val_accuracy: 0.8835\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 74s 2s/step - loss: 0.3096 - accuracy: 0.8831 - val_loss: 0.3399 - val_accuracy: 0.8835\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 73s 2s/step - loss: 0.2937 - accuracy: 0.8847 - val_loss: 0.3244 - val_accuracy: 0.8814\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 75s 2s/step - loss: 0.2684 - accuracy: 0.8898 - val_loss: 0.3207 - val_accuracy: 0.8856\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 71s 2s/step - loss: 0.2615 - accuracy: 0.8992 - val_loss: 0.3080 - val_accuracy: 0.8898\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 74s 2s/step - loss: 0.2214 - accuracy: 0.9102 - val_loss: 0.3041 - val_accuracy: 0.8856\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 74s 2s/step - loss: 0.1962 - accuracy: 0.9199 - val_loss: 0.2928 - val_accuracy: 0.8962\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 74s 2s/step - loss: 0.1833 - accuracy: 0.9309 - val_loss: 0.2955 - val_accuracy: 0.8877\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.2955 - accuracy: 0.8877\n",
            "\n",
            "Validation Accuracy for Fold-5: 0.8877118825912476\n",
            "==============================================================\n",
            "\n",
            "\n",
            "Average accuracy: 0.8824\n",
            "Average loss: 0.1772\n"
          ]
        }
      ]
    }
  ]
}