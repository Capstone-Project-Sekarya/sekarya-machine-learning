{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramaastra/sekarya-machine-learning/blob/main/sekarya_model_with_kfold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sekarya Machine Learning Model (Development)\n",
        "\n",
        "This notebook containing some experiments of machine learning model development for Sekarya's main feature, to classify wheter an artwork is generated by AI or not.\n",
        "\n",
        "For the model itself, the training will be done with a custom dataset we've collected below. For addition to the imbalanced ai_generated class in the dataset, we also add more data from Kaggle.\n",
        "\n",
        "- [Sekarya Dataset](https://drive.google.com/drive/folders/1W_DN02xlxOB9M_P27_TJJNuhdxEQY9Kf?usp=drive_link)\n",
        "- [Addition AI-generated Dataset](https://www.kaggle.com/datasets/gauravduttakiit/dalle-recognition-dataset)"
      ],
      "metadata": {
        "id": "Chtr4unu9ie6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Dataset"
      ],
      "metadata": {
        "id": "feFmcw7I9ZJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the Sekarya Dataset from Google Drive"
      ],
      "metadata": {
        "id": "Tzm6AWlwCp9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II3igpiWR7Tr",
        "outputId": "aa4cb4ca-bff8-4913-8a12-52422899f762"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/New-Sekarya-Dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXmbYIQgBKUy",
        "outputId": "6ea984b5-e588-43ad-9657-c22147464653"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dataset_dir = '/content/drive/MyDrive/New-Sekarya-Dataset/'\n",
        "os.listdir(drive_dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isu749ilFFE8",
        "outputId": "1f1da556-0ea1-4db6-adcb-a2b1e00bfadc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_train_dir = os.path.join(drive_dataset_dir, 'train')\n",
        "os.listdir(drive_train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCChtkojFb9H",
        "outputId": "dad270a6-fce4-467b-c74e-ddd718f47367"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ai_generated', 'non_ai_generated']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_train_fake_dir = os.path.join(drive_train_dir, 'ai_generated')\n",
        "drive_train_real_dir = os.path.join(drive_train_dir, 'non_ai_generated')\n",
        "\n",
        "print(f'There are {len(os.listdir(drive_train_fake_dir))} images of fake (AI-generated) artworks for training.\\n')\n",
        "print(f'There are {len(os.listdir(drive_train_real_dir))} images of real (human-made artworks) images for training.\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Th0Hlheazc",
        "outputId": "2af902be-b071-49b1-acf2-46c4be8a9f61"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 331 images of fake (AI-generated) artworks for training.\n",
            "\n",
            "There are 2501 images of real (human-made artworks) images for training.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Additional Dataset from Kaggle"
      ],
      "metadata": {
        "id": "nXVbri03EVZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "if not(os.path.exists(\"kaggle.json\")):\n",
        "  files.upload()\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "FedoizgmEqan",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "04e6da98-a4bb-4657-aceb-5bef7cb5db84"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-889618dd-fc7a-43c5-8f92-cbeeb6af36ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-889618dd-fc7a-43c5-8f92-cbeeb6af36ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.16.tar.gz (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110683 sha256=b13c41fddab86b4b2fc22187a7f2e69bebd7354f93f60e7f945bb075e8d93878\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/4b/fb/736478af5e8004810081a06259f9aa2f7c3329fc5d03c2c412\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.16\n",
            "    Uninstalling kaggle-1.5.16:\n",
            "      Successfully uninstalled kaggle-1.5.16\n",
            "Successfully installed kaggle-1.5.16\n",
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = 'gauravduttakiit/dalle-recognition-dataset'\n",
        "dataset_name = dataset_url.split('/')[1]\n",
        "!kaggle datasets download -d  {dataset_url}\n",
        "!mkdir {dataset_name}\n",
        "!unzip -q {dataset_name}.zip -d {dataset_name}\n",
        "!rm -f {dataset_name}.zip"
      ],
      "metadata": {
        "id": "b9ydB0CEE78z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2189e35-f497-45c7-bc6b-27b6e69e5039"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dalle-recognition-dataset.zip to /content\n",
            "100% 1.35G/1.35G [01:21<00:00, 17.1MB/s]\n",
            "100% 1.35G/1.35G [01:21<00:00, 17.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_train_fake_dir = f'/content/{dataset_name}/train/fake'\n",
        "print(f'There are {len(os.listdir(kaggle_train_fake_dir))} additional images of fake (AI-generated) artworks for training.\\n')"
      ],
      "metadata": {
        "id": "EtgQOmnCFky1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e1d8f4-d1fc-4a1a-e258-23f76553be7d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2057 additional images of fake (AI-generated) artworks for training.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Storing Data File Paths and Labels to a List"
      ],
      "metadata": {
        "id": "fB4SjOBpG-dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Dataset from Google Drive\n",
        "class_labels = os.listdir(drive_train_dir)\n",
        "for class_label in class_labels:\n",
        "  class_data_path = os.path.join(drive_train_dir, class_label)\n",
        "  for filename in os.listdir(class_data_path):\n",
        "    file_path = os.path.join(class_data_path, filename)\n",
        "    images.append(file_path)\n",
        "    labels.append(class_label)\n",
        "\n",
        "# Additional AI-generated class data from Kaggle\n",
        "for filename in os.listdir(kaggle_train_fake_dir):\n",
        "  file_path = os.path.join(kaggle_train_fake_dir, filename)\n",
        "  images.append(file_path)\n",
        "  labels.append('ai_generated')\n",
        "\n",
        "print(f'There are {len(images)} images will be splitted with K-fold cross-validation technique.\\n')"
      ],
      "metadata": {
        "id": "Gnpr0ziXe5vZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9ddf3d-0238-486b-cea9-f01ec725d6f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4889 images will be splitted with K-fold cross-validation technique.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Model Architecture"
      ],
      "metadata": {
        "id": "Jb-c3ysGKWNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "ABmtGn8wR_zf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining a Function to Handle Model Creation"
      ],
      "metadata": {
        "id": "Gp6xJeKZKguD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(pretrained=False):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  if pretrained:\n",
        "    vgg19 = VGG19(input_shape=(224, 224, 3),\n",
        "                            include_top=False,\n",
        "                            weights='imagenet')\n",
        "\n",
        "    for layer in vgg19.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "    model.add(vgg19)\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "  else:\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dropout(0.1))\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                loss=BinaryCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Q7cbd8sFhNcz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining EarlyStopping Callback"
      ],
      "metadata": {
        "id": "yyXBfK7l9Wjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=5,\n",
        "                               mode='min',\n",
        "                               restore_best_weights=True)"
      ],
      "metadata": {
        "id": "8_jvBHYwPDMk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Models"
      ],
      "metadata": {
        "id": "3fRZr2XTizuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = create_model()\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8zQMXNfi4a2",
        "outputId": "c25b17ea-9051-4027-dc03-44bd3c568a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPooli  (None, 111, 111, 32)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPooli  (None, 54, 54, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPooli  (None, 26, 26, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 86528)             0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 86528)             0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 64)                5537856   \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5633217 (21.49 MB)\n",
            "Trainable params: 5633217 (21.49 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19_model = create_model(pretrained=True)\n",
        "vgg19_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yplRRTFjNDZ",
        "outputId": "ebd0878d-1f41-4263-d7e6-8d5f6c46f86a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 4s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23244097 (88.67 MB)\n",
            "Trainable params: 3219713 (12.28 MB)\n",
            "Non-trainable params: 20024384 (76.39 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model with K-fold Cross-validation"
      ],
      "metadata": {
        "id": "eBURFE8sOXeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 5\n",
        "kfold = StratifiedKFold(n_splits=num_folds)"
      ],
      "metadata": {
        "id": "h0xHmNypTQ8L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_kfold(model, model_name):\n",
        "  for k, (train_indices, val_indices) in enumerate(kfold.split(images, labels)):\n",
        "    print(f'[Processing Fold-{k}...]\\n')\n",
        "\n",
        "    # Creating lists for images and labels based on the train and val indices\n",
        "    x_train = [images[i] for i in train_indices]\n",
        "    y_train = [labels[i] for i in train_indices]\n",
        "    x_val = [images[i] for i in val_indices]\n",
        "    y_val = [labels[i] for i in val_indices]\n",
        "\n",
        "    # Creating dataframe for each train and val list\n",
        "    train_df = pd.DataFrame({\n",
        "      'image': x_train,\n",
        "      'label': y_train\n",
        "    })\n",
        "    val_df = pd.DataFrame({\n",
        "      'image': x_val,\n",
        "      'label': y_val\n",
        "    })\n",
        "\n",
        "    # Creating the image generator to process the images\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255.0)\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255.0)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(train_df,\n",
        "                                                        x_col='image',\n",
        "                                                        y_col='label',\n",
        "                                                        target_size=(224, 224),\n",
        "                                                        batch_size=32,\n",
        "                                                        color_mode='rgb',\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "    val_generator = val_datagen.flow_from_dataframe(val_df,\n",
        "                                                    x_col='image',\n",
        "                                                    y_col='label',\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=32,\n",
        "                                                    color_mode='rgb',\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "    print()\n",
        "\n",
        "    # Train the model for this fold\n",
        "    history = model.fit(train_generator,\n",
        "                        epochs=20,\n",
        "                        validation_data=val_generator,\n",
        "                        verbose=1,\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    _, accuracy = model.evaluate(val_generator, verbose=0)\n",
        "    print(f'\\nValidation accuracy for fold-{k}: {accuracy:.4f}')\n",
        "\n",
        "    print('\\n==============================================================\\n')\n",
        "\n",
        "  # Save the model into models directory\n",
        "  model.save(f'/content/models/{model_name}.h5')"
      ],
      "metadata": {
        "id": "IpoetgWKjzz2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_kfold(cnn_model, 'cnn_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNUuqGeWjcib",
        "outputId": "b16811e8-3074-4e0f-c187-96bc414d04d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Processing Fold-0...]\n",
            "\n",
            "Found 3911 validated image filenames belonging to 2 classes.\n",
            "Found 978 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Epoch 1/20\n",
            "123/123 [==============================] - 77s 611ms/step - loss: 0.6630 - accuracy: 0.5855 - val_loss: 0.5474 - val_accuracy: 0.6810\n",
            "Epoch 2/20\n",
            "123/123 [==============================] - 74s 604ms/step - loss: 0.5528 - accuracy: 0.7149 - val_loss: 0.4134 - val_accuracy: 0.8231\n",
            "Epoch 3/20\n",
            "123/123 [==============================] - 75s 614ms/step - loss: 0.5053 - accuracy: 0.7535 - val_loss: 0.3563 - val_accuracy: 0.8487\n",
            "Epoch 4/20\n",
            "123/123 [==============================] - 85s 695ms/step - loss: 0.4561 - accuracy: 0.7914 - val_loss: 0.4189 - val_accuracy: 0.7730\n",
            "Epoch 5/20\n",
            "123/123 [==============================] - 76s 616ms/step - loss: 0.4308 - accuracy: 0.8039 - val_loss: 0.2824 - val_accuracy: 0.8967\n",
            "Epoch 6/20\n",
            "123/123 [==============================] - 75s 610ms/step - loss: 0.3962 - accuracy: 0.8231 - val_loss: 0.2822 - val_accuracy: 0.9049\n",
            "Epoch 7/20\n",
            "123/123 [==============================] - 76s 613ms/step - loss: 0.3451 - accuracy: 0.8537 - val_loss: 0.2468 - val_accuracy: 0.9100\n",
            "Epoch 8/20\n",
            "123/123 [==============================] - 75s 613ms/step - loss: 0.2984 - accuracy: 0.8814 - val_loss: 0.2569 - val_accuracy: 0.8998\n",
            "Epoch 9/20\n",
            "123/123 [==============================] - 75s 616ms/step - loss: 0.2903 - accuracy: 0.8788 - val_loss: 0.2463 - val_accuracy: 0.9141\n",
            "Epoch 10/20\n",
            "123/123 [==============================] - 75s 612ms/step - loss: 0.2428 - accuracy: 0.9149 - val_loss: 0.2534 - val_accuracy: 0.8957\n",
            "Epoch 11/20\n",
            "123/123 [==============================] - 74s 605ms/step - loss: 0.2031 - accuracy: 0.9282 - val_loss: 0.2328 - val_accuracy: 0.9059\n",
            "Epoch 12/20\n",
            "123/123 [==============================] - 75s 611ms/step - loss: 0.1819 - accuracy: 0.9407 - val_loss: 0.2344 - val_accuracy: 0.9070\n",
            "Epoch 13/20\n",
            "123/123 [==============================] - 75s 611ms/step - loss: 0.1502 - accuracy: 0.9504 - val_loss: 0.2500 - val_accuracy: 0.9070\n",
            "Epoch 14/20\n",
            "123/123 [==============================] - 76s 617ms/step - loss: 0.1254 - accuracy: 0.9645 - val_loss: 0.2042 - val_accuracy: 0.9274\n",
            "Epoch 15/20\n",
            "123/123 [==============================] - 73s 596ms/step - loss: 0.1088 - accuracy: 0.9660 - val_loss: 0.2984 - val_accuracy: 0.8978\n",
            "Epoch 16/20\n",
            "123/123 [==============================] - 73s 596ms/step - loss: 0.1035 - accuracy: 0.9662 - val_loss: 0.2605 - val_accuracy: 0.9059\n",
            "Epoch 17/20\n",
            "123/123 [==============================] - 75s 609ms/step - loss: 0.0819 - accuracy: 0.9783 - val_loss: 0.2655 - val_accuracy: 0.9162\n",
            "Epoch 18/20\n",
            "123/123 [==============================] - 74s 606ms/step - loss: 0.0651 - accuracy: 0.9844 - val_loss: 0.2040 - val_accuracy: 0.9294\n",
            "Epoch 19/20\n",
            "123/123 [==============================] - 74s 603ms/step - loss: 0.0593 - accuracy: 0.9844 - val_loss: 0.2518 - val_accuracy: 0.9151\n",
            "Epoch 20/20\n",
            "123/123 [==============================] - 74s 599ms/step - loss: 0.0450 - accuracy: 0.9903 - val_loss: 0.2611 - val_accuracy: 0.9192\n",
            "\n",
            "Validation accuracy for fold-0: 0.9192\n",
            "\n",
            "==============================================================\n",
            "\n",
            "[Processing Fold-1...]\n",
            "\n",
            "Found 3911 validated image filenames belonging to 2 classes.\n",
            "Found 978 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Epoch 1/20\n",
            "123/123 [==============================] - 75s 614ms/step - loss: 0.1171 - accuracy: 0.9660 - val_loss: 0.0345 - val_accuracy: 0.9928\n",
            "Epoch 2/20\n",
            "123/123 [==============================] - 75s 610ms/step - loss: 0.0663 - accuracy: 0.9826 - val_loss: 0.0227 - val_accuracy: 0.9949\n",
            "Epoch 3/20\n",
            "123/123 [==============================] - 73s 595ms/step - loss: 0.0552 - accuracy: 0.9867 - val_loss: 0.0749 - val_accuracy: 0.9744\n",
            "Epoch 4/20\n",
            "123/123 [==============================] - 73s 594ms/step - loss: 0.0447 - accuracy: 0.9882 - val_loss: 0.0206 - val_accuracy: 0.9959\n",
            "Epoch 5/20\n",
            "123/123 [==============================] - 74s 599ms/step - loss: 0.0288 - accuracy: 0.9954 - val_loss: 0.0412 - val_accuracy: 0.9826\n",
            "Epoch 6/20\n",
            "123/123 [==============================] - 74s 605ms/step - loss: 0.0219 - accuracy: 0.9982 - val_loss: 0.0291 - val_accuracy: 0.9898\n",
            "Epoch 7/20\n",
            "123/123 [==============================] - 76s 623ms/step - loss: 0.0162 - accuracy: 0.9987 - val_loss: 0.0312 - val_accuracy: 0.9898\n",
            "Epoch 8/20\n",
            "123/123 [==============================] - 74s 604ms/step - loss: 0.0171 - accuracy: 0.9982 - val_loss: 0.0507 - val_accuracy: 0.9785\n",
            "Epoch 9/20\n",
            "123/123 [==============================] - 74s 604ms/step - loss: 0.0257 - accuracy: 0.9939 - val_loss: 0.0630 - val_accuracy: 0.9744\n",
            "\n",
            "Validation accuracy for fold-1: 0.9959\n",
            "\n",
            "==============================================================\n",
            "\n",
            "[Processing Fold-2...]\n",
            "\n",
            "Found 3911 validated image filenames belonging to 2 classes.\n",
            "Found 978 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Epoch 1/20\n",
            "123/123 [==============================] - 76s 617ms/step - loss: 0.0349 - accuracy: 0.9928 - val_loss: 0.0313 - val_accuracy: 0.9969\n",
            "Epoch 2/20\n",
            "123/123 [==============================] - 75s 615ms/step - loss: 0.0216 - accuracy: 0.9967 - val_loss: 0.0258 - val_accuracy: 0.9990\n",
            "Epoch 3/20\n",
            "123/123 [==============================] - 74s 599ms/step - loss: 0.0147 - accuracy: 0.9987 - val_loss: 0.0212 - val_accuracy: 0.9980\n",
            "Epoch 4/20\n",
            "123/123 [==============================] - 73s 593ms/step - loss: 0.0167 - accuracy: 0.9987 - val_loss: 0.0296 - val_accuracy: 0.9959\n",
            "Epoch 5/20\n",
            "123/123 [==============================] - 76s 620ms/step - loss: 0.0099 - accuracy: 0.9995 - val_loss: 0.0229 - val_accuracy: 0.9980\n",
            "Epoch 6/20\n",
            "123/123 [==============================] - 76s 614ms/step - loss: 0.0400 - accuracy: 0.9885 - val_loss: 0.0527 - val_accuracy: 0.9867\n",
            "Epoch 7/20\n",
            "123/123 [==============================] - 74s 598ms/step - loss: 0.0122 - accuracy: 0.9995 - val_loss: 0.0370 - val_accuracy: 0.9888\n",
            "Epoch 8/20\n",
            "123/123 [==============================] - 74s 603ms/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 0.0287 - val_accuracy: 0.9939\n",
            "\n",
            "Validation accuracy for fold-2: 0.9980\n",
            "\n",
            "==============================================================\n",
            "\n",
            "[Processing Fold-3...]\n",
            "\n",
            "Found 3911 validated image filenames belonging to 2 classes.\n",
            "Found 978 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Epoch 1/20\n",
            "123/123 [==============================] - 86s 695ms/step - loss: 0.0190 - accuracy: 0.9967 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "123/123 [==============================] - 73s 588ms/step - loss: 0.0144 - accuracy: 0.9982 - val_loss: 0.0190 - val_accuracy: 0.9990\n",
            "Epoch 3/20\n",
            "123/123 [==============================] - 75s 612ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.0171 - val_accuracy: 0.9969\n",
            "Epoch 4/20\n",
            "123/123 [==============================] - 75s 611ms/step - loss: 0.0407 - accuracy: 0.9880 - val_loss: 0.1108 - val_accuracy: 0.9683\n",
            "Epoch 5/20\n",
            "123/123 [==============================] - 74s 604ms/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 0.0431 - val_accuracy: 0.9836\n",
            "Epoch 6/20\n",
            "123/123 [==============================] - 73s 596ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.0169 - val_accuracy: 0.9969\n",
            "\n",
            "Validation accuracy for fold-3: 1.0000\n",
            "\n",
            "==============================================================\n",
            "\n",
            "[Processing Fold-4...]\n",
            "\n",
            "Found 3912 validated image filenames belonging to 2 classes.\n",
            "Found 977 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Epoch 1/20\n",
            "123/123 [==============================] - 74s 602ms/step - loss: 0.0168 - accuracy: 0.9974 - val_loss: 0.0144 - val_accuracy: 0.9980\n",
            "Epoch 2/20\n",
            "123/123 [==============================] - 73s 595ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0269 - val_accuracy: 0.9949\n",
            "Epoch 3/20\n",
            "123/123 [==============================] - 75s 607ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.0191 - val_accuracy: 0.9990\n",
            "Epoch 4/20\n",
            "123/123 [==============================] - 74s 600ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.0173 - val_accuracy: 0.9959\n",
            "Epoch 5/20\n",
            "123/123 [==============================] - 73s 597ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.0133 - val_accuracy: 0.9980\n",
            "Epoch 6/20\n",
            "123/123 [==============================] - 76s 615ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0365 - val_accuracy: 0.9928\n",
            "Epoch 7/20\n",
            "123/123 [==============================] - 74s 606ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0177 - val_accuracy: 0.9959\n",
            "Epoch 8/20\n",
            "123/123 [==============================] - 74s 606ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0140 - val_accuracy: 0.9980\n",
            "Epoch 9/20\n",
            "123/123 [==============================] - 74s 601ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0131 - val_accuracy: 0.9980\n",
            "Epoch 10/20\n",
            "123/123 [==============================] - 73s 599ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0122 - val_accuracy: 0.9969\n",
            "Epoch 11/20\n",
            "123/123 [==============================] - 76s 617ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9826\n",
            "Epoch 12/20\n",
            "123/123 [==============================] - 72s 584ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0260 - val_accuracy: 0.9928\n",
            "Epoch 13/20\n",
            "123/123 [==============================] - 71s 577ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9959\n",
            "Epoch 14/20\n",
            "123/123 [==============================] - 73s 583ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9959\n",
            "Epoch 15/20\n",
            "123/123 [==============================] - 73s 592ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9969\n",
            "\n",
            "Validation accuracy for fold-4: 0.9969\n",
            "\n",
            "==============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_kfold(vgg19_model, 'vgg19_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc90w67JkJPr",
        "outputId": "c2c3a7d9-ef71-4c63-c13d-85a6c7bbca54"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Processing Fold-0...]\n",
            "\n",
            "Found 3911 validated image filenames belonging to 2 classes.\n",
            "Found 978 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Epoch 1/20\n",
            "123/123 [==============================] - 85s 666ms/step - loss: 0.5523 - accuracy: 0.7100 - val_loss: 0.3838 - val_accuracy: 0.8333\n",
            "Epoch 2/20\n",
            "123/123 [==============================] - 82s 666ms/step - loss: 0.3887 - accuracy: 0.8284 - val_loss: 0.3390 - val_accuracy: 0.8609\n",
            "Epoch 3/20\n",
            "123/123 [==============================] - 89s 716ms/step - loss: 0.3185 - accuracy: 0.8722 - val_loss: 0.3200 - val_accuracy: 0.8671\n",
            "Epoch 4/20\n",
            "123/123 [==============================] - 80s 646ms/step - loss: 0.2564 - accuracy: 0.8980 - val_loss: 0.2884 - val_accuracy: 0.8763\n",
            "Epoch 5/20\n",
            "123/123 [==============================] - 90s 735ms/step - loss: 0.1998 - accuracy: 0.9322 - val_loss: 0.3094 - val_accuracy: 0.8691\n",
            "Epoch 6/20\n",
            "123/123 [==============================] - 90s 732ms/step - loss: 0.1667 - accuracy: 0.9427 - val_loss: 0.2938 - val_accuracy: 0.8834\n",
            "Epoch 7/20\n",
            "123/123 [==============================] - 90s 729ms/step - loss: 0.1429 - accuracy: 0.9532 - val_loss: 0.3407 - val_accuracy: 0.8630\n",
            "Epoch 8/20\n",
            "123/123 [==============================] - 80s 651ms/step - loss: 0.1328 - accuracy: 0.9568 - val_loss: 0.3124 - val_accuracy: 0.8732\n",
            "Epoch 9/20\n",
            "123/123 [==============================] - 79s 647ms/step - loss: 0.0909 - accuracy: 0.9760 - val_loss: 0.3867 - val_accuracy: 0.8487\n",
            "\n",
            "Validation accuracy for fold-0: 0.8763\n",
            "\n",
            "==============================================================\n",
            "\n",
            "[Processing Fold-1...]\n",
            "\n",
            "Found 3911 validated image filenames belonging to 2 classes.\n",
            "Found 978 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Epoch 1/20\n",
            "123/123 [==============================] - 84s 683ms/step - loss: 0.2593 - accuracy: 0.8987 - val_loss: 0.2159 - val_accuracy: 0.8988\n",
            "Epoch 2/20\n",
            "123/123 [==============================] - 80s 650ms/step - loss: 0.2152 - accuracy: 0.9110 - val_loss: 0.1657 - val_accuracy: 0.9438\n",
            "Epoch 3/20\n",
            "123/123 [==============================] - 80s 645ms/step - loss: 0.1539 - accuracy: 0.9460 - val_loss: 0.1629 - val_accuracy: 0.9356\n",
            "Epoch 4/20\n",
            "123/123 [==============================] - 82s 665ms/step - loss: 0.1304 - accuracy: 0.9581 - val_loss: 0.1906 - val_accuracy: 0.9172\n",
            "Epoch 5/20\n",
            "123/123 [==============================] - 82s 668ms/step - loss: 0.0933 - accuracy: 0.9752 - val_loss: 0.1915 - val_accuracy: 0.9182\n",
            "Epoch 6/20\n",
            "123/123 [==============================] - 81s 664ms/step - loss: 0.0827 - accuracy: 0.9757 - val_loss: 0.1557 - val_accuracy: 0.9448\n",
            "Epoch 7/20\n",
            "123/123 [==============================] - 82s 666ms/step - loss: 0.0914 - accuracy: 0.9729 - val_loss: 0.1848 - val_accuracy: 0.9284\n",
            "Epoch 8/20\n",
            "123/123 [==============================] - 84s 687ms/step - loss: 0.0595 - accuracy: 0.9870 - val_loss: 0.1825 - val_accuracy: 0.9325\n",
            "Epoch 9/20\n",
            "123/123 [==============================] - 80s 653ms/step - loss: 0.0440 - accuracy: 0.9905 - val_loss: 0.2573 - val_accuracy: 0.8885\n",
            "Epoch 10/20\n",
            "123/123 [==============================] - 81s 660ms/step - loss: 0.0430 - accuracy: 0.9898 - val_loss: 0.2185 - val_accuracy: 0.9070\n",
            "Epoch 11/20\n",
            "123/123 [==============================] - 83s 676ms/step - loss: 0.0387 - accuracy: 0.9900 - val_loss: 0.2307 - val_accuracy: 0.9059\n",
            "\n",
            "Validation accuracy for fold-1: 0.9448\n",
            "\n",
            "==============================================================\n",
            "\n",
            "[Processing Fold-2...]\n",
            "\n",
            "Found 3911 validated image filenames belonging to 2 classes.\n",
            "Found 978 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Epoch 1/20\n",
            "123/123 [==============================] - 80s 652ms/step - loss: 0.1208 - accuracy: 0.9547 - val_loss: 0.0873 - val_accuracy: 0.9734\n",
            "Epoch 2/20\n",
            "123/123 [==============================] - 80s 650ms/step - loss: 0.0807 - accuracy: 0.9737 - val_loss: 0.0694 - val_accuracy: 0.9836\n",
            "Epoch 3/20\n",
            "123/123 [==============================] - 81s 656ms/step - loss: 0.0720 - accuracy: 0.9757 - val_loss: 0.0801 - val_accuracy: 0.9734\n",
            "Epoch 4/20\n",
            "123/123 [==============================] - 83s 673ms/step - loss: 0.0501 - accuracy: 0.9882 - val_loss: 0.1345 - val_accuracy: 0.9397\n",
            "Epoch 5/20\n",
            "123/123 [==============================] - 81s 655ms/step - loss: 0.0411 - accuracy: 0.9908 - val_loss: 0.0818 - val_accuracy: 0.9724\n",
            "Epoch 6/20\n",
            "123/123 [==============================] - 80s 655ms/step - loss: 0.0389 - accuracy: 0.9898 - val_loss: 0.0841 - val_accuracy: 0.9703\n",
            "Epoch 7/20\n",
            "123/123 [==============================] - 80s 656ms/step - loss: 0.0304 - accuracy: 0.9936 - val_loss: 0.1052 - val_accuracy: 0.9581\n",
            "\n",
            "Validation accuracy for fold-2: 0.9836\n",
            "\n",
            "==============================================================\n",
            "\n",
            "[Processing Fold-3...]\n",
            "\n",
            "Found 3911 validated image filenames belonging to 2 classes.\n",
            "Found 978 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Epoch 1/20\n",
            "123/123 [==============================] - 84s 682ms/step - loss: 0.0717 - accuracy: 0.9783 - val_loss: 0.2861 - val_accuracy: 0.8456\n",
            "Epoch 2/20\n",
            "123/123 [==============================] - 81s 662ms/step - loss: 0.0628 - accuracy: 0.9808 - val_loss: 0.0697 - val_accuracy: 0.9826\n",
            "Epoch 3/20\n",
            "123/123 [==============================] - 92s 749ms/step - loss: 0.0592 - accuracy: 0.9811 - val_loss: 0.0648 - val_accuracy: 0.9816\n",
            "Epoch 4/20\n",
            "123/123 [==============================] - 81s 659ms/step - loss: 0.0416 - accuracy: 0.9890 - val_loss: 0.0610 - val_accuracy: 0.9847\n",
            "Epoch 5/20\n",
            "123/123 [==============================] - 83s 675ms/step - loss: 0.0304 - accuracy: 0.9934 - val_loss: 0.0511 - val_accuracy: 0.9836\n",
            "Epoch 6/20\n",
            "123/123 [==============================] - 82s 670ms/step - loss: 0.0225 - accuracy: 0.9959 - val_loss: 0.0585 - val_accuracy: 0.9806\n",
            "Epoch 7/20\n",
            "123/123 [==============================] - 82s 670ms/step - loss: 0.0343 - accuracy: 0.9908 - val_loss: 0.0711 - val_accuracy: 0.9714\n",
            "Epoch 8/20\n",
            "123/123 [==============================] - 83s 676ms/step - loss: 0.0237 - accuracy: 0.9951 - val_loss: 0.1012 - val_accuracy: 0.9622\n",
            "Epoch 9/20\n",
            "123/123 [==============================] - 81s 656ms/step - loss: 0.0197 - accuracy: 0.9964 - val_loss: 0.0654 - val_accuracy: 0.9724\n",
            "Epoch 10/20\n",
            "123/123 [==============================] - 83s 669ms/step - loss: 0.0132 - accuracy: 0.9982 - val_loss: 0.0652 - val_accuracy: 0.9714\n",
            "\n",
            "Validation accuracy for fold-3: 0.9836\n",
            "\n",
            "==============================================================\n",
            "\n",
            "[Processing Fold-4...]\n",
            "\n",
            "Found 3912 validated image filenames belonging to 2 classes.\n",
            "Found 977 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Epoch 1/20\n",
            "123/123 [==============================] - 88s 714ms/step - loss: 0.0523 - accuracy: 0.9811 - val_loss: 0.0264 - val_accuracy: 0.9959\n",
            "Epoch 2/20\n",
            "123/123 [==============================] - 82s 668ms/step - loss: 0.0605 - accuracy: 0.9765 - val_loss: 0.0302 - val_accuracy: 0.9939\n",
            "Epoch 3/20\n",
            "123/123 [==============================] - 83s 674ms/step - loss: 0.0288 - accuracy: 0.9913 - val_loss: 0.0262 - val_accuracy: 0.9969\n",
            "Epoch 4/20\n",
            "123/123 [==============================] - 79s 639ms/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 0.1390 - val_accuracy: 0.9376\n",
            "Epoch 5/20\n",
            "123/123 [==============================] - 82s 667ms/step - loss: 0.0235 - accuracy: 0.9954 - val_loss: 0.0326 - val_accuracy: 0.9898\n",
            "Epoch 6/20\n",
            "123/123 [==============================] - 81s 657ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.0351 - val_accuracy: 0.9867\n",
            "Epoch 7/20\n",
            "123/123 [==============================] - 80s 653ms/step - loss: 0.0153 - accuracy: 0.9964 - val_loss: 0.0367 - val_accuracy: 0.9877\n",
            "Epoch 8/20\n",
            "123/123 [==============================] - 79s 644ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.0505 - val_accuracy: 0.9846\n",
            "\n",
            "Validation accuracy for fold-4: 0.9969\n",
            "\n",
            "==============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model with Confusion Matrix"
      ],
      "metadata": {
        "id": "7SmLCznKr16Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the Test Set from Kaggle"
      ],
      "metadata": {
        "id": "VoS9z6GxsVay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "if not(os.path.exists(\"kaggle.json\")):\n",
        "  files.upload()\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "vt01UOfIsUQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e17fafe-3ae0-41e3-fb16-ff42678d3236"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle\n",
            "  Using cached kaggle-1.5.16-py3-none-any.whl\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.16\n",
            "    Uninstalling kaggle-1.5.16:\n",
            "      Successfully uninstalled kaggle-1.5.16\n",
            "Successfully installed kaggle-1.5.16\n",
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = 'macayanpioloc/ai-generated-and-human-made-painting'\n",
        "dataset_name = dataset_url.split('/')[1]\n",
        "!kaggle datasets download -d  {dataset_url}\n",
        "!mkdir {dataset_name}\n",
        "!unzip -q {dataset_name}.zip -d {dataset_name}\n",
        "!rm -f {dataset_name}.zip"
      ],
      "metadata": {
        "id": "8ts7HrmAr5qj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de14ebf-cb47-4c91-9ba3-23e313ab938c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ai-generated-and-human-made-painting.zip to /content\n",
            "100% 406M/407M [00:23<00:00, 17.7MB/s]\n",
            "100% 407M/407M [00:23<00:00, 18.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = f'/content/{dataset_name}/224/val'\n",
        "os.listdir(test_dir)"
      ],
      "metadata": {
        "id": "58H3Wohasaxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd834690-6a7f-44a6-93ad-8feff9601e28"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI_GENERATED', 'NON_AI_GENERATED']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating Model Predictions on the Test Set"
      ],
      "metadata": {
        "id": "yRF1blF8yN1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255.0)\n",
        "test_generator = test_datagen.flow_from_directory(directory=test_dir,\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='binary',\n",
        "                                                  target_size=(224, 224))"
      ],
      "metadata": {
        "id": "jGakIoeCsfgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3853ac2-3977-4906-87fb-c7f985c64004"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5884 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# True label for the test set\n",
        "y_true = test_generator.classes"
      ],
      "metadata": {
        "id": "bYpND4xlt9d9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model\n",
        "model = tf.keras.models.load_model('/content/models/vgg19_model.h5')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "v2Lc9kMVsgsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca66211-d354-44d1-f02c-39fb1eaab9ff"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23244097 (88.67 MB)\n",
            "Trainable params: 3219713 (12.28 MB)\n",
            "Non-trainable params: 20024384 (76.39 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating predictions with the model to the test set\n",
        "predictions = model.predict(test_generator)"
      ],
      "metadata": {
        "id": "MUwS1Ggbsp6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6d753b-f754-4a3c-a30e-7e3ca8f77218"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184/184 [==============================] - 36s 193ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the probabilites into binary class\n",
        "threshold = 0.5\n",
        "y_pred = (predictions > threshold).astype(int)"
      ],
      "metadata": {
        "id": "U1R1auARvQC0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=['ai_generated', 'non_ai_generated'])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "n6HI3C24uexN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "3ef178ec-1a0d-4249-fead-362d2ac203c9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7d2554507c40>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAGxCAYAAAAAk5BWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABS1ElEQVR4nO3de1yUZf7/8feAcj4JCYQCahpCHlMzvutx18Qy07SfW2lpamVqlqZh22oeUlyt3DTT1EptbbPSzNS1yDwfKik0FfEceHY1RTAEmfv3B8vYpI6MMwgzvZ77uB8P576u+5rrZpnmw+c63CbDMAwBAADALXiUdwcAAADgPAR3AAAAboTgDgAAwI0Q3AEAALgRgjsAAAA3QnAHAADgRgjuAAAA3AjBHQAAgBupVN4dAEqYzWYdPXpUgYGBMplM5d0dAIAdDMPQ+fPnFRUVJQ+Psssd5efnq6CgwClteXl5ycfHxyltVSQEd6gwjh49qujo6PLuBgDAAdnZ2apevXqZtJ2fn6+asQE6frLIKe1FRkbq4MGDbhfgEdyhwggMDJQkNXhopDwru9cHDSjxzZh3y7sLQJnIyTUr9s5Dlv+Wl4WCggIdP1mkg2mxCgp0LDuYc96smk1+VkFBAcEdUFZKhmI9K/vI08u9PmhACUe/kICK7mZMqwkK9OCzZAPBHQAAcClFhllFhuNtuCuCOwAA4FLMMmSWY9Gdo9dXZOQ0AQAA3AjBHQAAcClmJ/2vtFJSUtSsWTMFBgYqPDxcXbp0UWZmplWd/Px8DRw4UGFhYQoICFC3bt104sQJqzpZWVnq2LGj/Pz8FB4eruHDh+vSpUtWddasWaM777xT3t7eql27tubOnWv3z4fgDgAAuJQiw3DKUVpr167VwIEDtWXLFqWmpqqwsFDt27dXXl6epc6QIUP0xRdf6JNPPtHatWt19OhRde3a9XKfi4rUsWNHFRQUaNOmTZo3b57mzp2rUaNGWeocPHhQHTt2VNu2bZWenq7nn39e/fr105dffmnXz8dkGHbcHVCGcnJyFBwcrMaPjGe1LNzWtxNnlHcXgDKRc96sKrcf0Llz5xQUFFQ27/G/74ns3dWcshVKdN0jN9TfU6dOKTw8XGvXrlWrVq107tw5Va1aVR9++KEeeughSdLu3bsVHx+vzZs36+6779Z//vMf3X///Tp69KgiIiIkSTNnzlRycrJOnTolLy8vJScna/ny5dqxY4flvR5++GGdPXtWK1euLHX/yNwBAACXUrKgwtFDKg4Yf3tcvHjxuu9/7tw5SVJoaKgkKS0tTYWFhWrXrp2lTt26dRUTE6PNmzdLkjZv3qz69etbAjtJSkpKUk5Ojnbu3Gmp89s2SuqUtFFaBHcAAMClmGWoyMGjJLiLjo5WcHCw5UhJSbH93maznn/+ef3pT39SvXr1JEnHjx+Xl5eXQkJCrOpGRETo+PHjljq/DexKykvKbNXJycnRr7/+WuqfD1uhAACAP6zs7GyrYVlvb2+b9QcOHKgdO3Zow4YNZd21G0ZwBwAAXIoz97kLCgoq9Zy7QYMGadmyZVq3bp3V83MjIyNVUFCgs2fPWmXvTpw4ocjISEud7777zqq9ktW0v63z+xW2J06cUFBQkHx9fUt9bwzLAgAAl3KzV8sahqFBgwbps88+0zfffKOaNWtalTdp0kSVK1fWqlWrLOcyMzOVlZWlxMRESVJiYqJ++uknnTx50lInNTVVQUFBSkhIsNT5bRsldUraKC0ydwAAwKWY/3c42kZpDRw4UB9++KE+//xzBQYGWubIBQcHy9fXV8HBwerbt6+GDh2q0NBQBQUF6dlnn1ViYqLuvvtuSVL79u2VkJCgxx57TJMmTdLx48f197//XQMHDrQMBffv319vvfWWXnzxRfXp00fffPONPv74Yy1fvtyueyNzBwAAYMOMGTN07tw5tWnTRrfeeqvlWLhwoaXOlClTdP/996tbt25q1aqVIiMjtXjxYku5p6enli1bJk9PTyUmJqpnz556/PHHNXbsWEudmjVravny5UpNTVXDhg31+uuva86cOUpKSrKrv+xzhwqDfe7wR8A+d3BXN3Ofu50Z4Qp0cJ+78+fNuiP+ZJn2t7wwLAsAAFxKkVF8ONqGu2JYFgAAwI2QuQMAAC7lZi+ocDUEdwAAwKWYZVKRTA634a4YlgUAAHAjZO4AAIBLMRvFh6NtuCuCOwAA4FKKnDAs6+j1FRnDsgAAAG6EzB0AAHApZO5sI7gDAAAuxWyYZDYcXC3r4PUVGcEdAABwKWTubGPOHQAAgBshcwcAAFxKkTxU5GB+qshJfamICO4AAIBLMZww585w4zl3DMsCAAC4ETJ3AADApbCgwjaCOwAA4FKKDA8VGQ7OuXPjx48xLAsAAOBGyNwBAACXYpZJZgfzU2a5b+qO4A4AALgU5tzZxrAsAACAGyFzBwAAXIpzFlQwLAsAAFAhFM+5c2xY1dHrKzKCOwAA4FLMTnj8mDsvqGDOHQAAgBshcwcAAFwKc+5sI7gDAAAuxSwP9rmzgWFZAAAAN0LmDgAAuJQiw6Qiw8FNjB28viIjuAMAAC6lyAmrZYsYlgUAAIArIHMHAABcitnwkNnB1bJmVssCAABUDAzL2sawLAAAgBshcwcAAFyKWY6vdjU7pysVEsEdAABwKc7ZxNh9By8J7gAAgEtxzuPH3De4c987AwAA+AMicwcAAFyKWSaZ5eicO55QAQAAUCEwLGub+94ZAADAHxCZOwAA4FKcs4mx++a3CO4AAIBLMRsmmR3d587B6ysy9w1bAQAA/oDI3AEAAJdidsKwLJsYAwAAVBBmw0NmB1e7Onp9Rea+dwYAAPAHROYOAAC4lCKZVOTgJsSOXl+REdwBAACXwrCsbQR3AADApRTJ8cxbkXO6UiG5b9gKAADwB0TmDgAAuBSGZW0juAMAAC6lyPBQkYPBmaPXV2Tue2cAAAB/QGTuAACASzFkktnBBRUGW6EAAABUDAzL2ua+dwYAAPAHROYOAAC4FLNhktlwbFjV0esrMoI7AADgUorkoSIHBx8dvb4ic987AwAA+AMicwcAAFwKw7K2kbkDAAAuxSwPpxz2WLdunTp16qSoqCiZTCYtWbLEqjw3N1eDBg1S9erV5evrq4SEBM2cOdOqTn5+vgYOHKiwsDAFBASoW7duOnHihFWdrKwsdezYUX5+fgoPD9fw4cN16dIlu/pKcAcAAFxKkWFyymGPvLw8NWzYUNOnT79q+dChQ7Vy5Ur961//UkZGhp5//nkNGjRIS5cutdQZMmSIvvjiC33yySdau3atjh49qq5du16+r6IidezYUQUFBdq0aZPmzZunuXPnatSoUXb1leAOAADgOu699169+uqrevDBB69avmnTJvXq1Utt2rRRjRo19NRTT6lhw4b67rvvJEnnzp3Tu+++qzfeeEN//vOf1aRJE73//vvatGmTtmzZIkn66quvtGvXLv3rX/9So0aNdO+992rcuHGaPn26CgoKSt1XgjsAAOBSSubcOXpIUk5OjtVx8eLFG+rT//3f/2np0qU6cuSIDMPQ6tWrtWfPHrVv316SlJaWpsLCQrVr185yTd26dRUTE6PNmzdLkjZv3qz69esrIiLCUicpKUk5OTnauXNnqftCcAcAAFyKYXjI7OBh/O8JFdHR0QoODrYcKSkpN9SnadOmKSEhQdWrV5eXl5c6dOig6dOnq1WrVpKk48ePy8vLSyEhIVbXRURE6Pjx45Y6vw3sSspLykqL1bIAAOAPKzs7W0FBQZbX3t7eN9TOtGnTtGXLFi1dulSxsbFat26dBg4cqKioKKts3c1AcAcAAFxKkUwqkmNbmZRcHxQUZBXc3Yhff/1Vf/vb3/TZZ5+pY8eOkqQGDRooPT1dr732mtq1a6fIyEgVFBTo7NmzVtm7EydOKDIyUpIUGRlpmaP32/KSstJiWBYAALgUs+GMeXfO609hYaEKCwvl4WEdVnl6espsNkuSmjRposqVK2vVqlWW8szMTGVlZSkxMVGSlJiYqJ9++kknT5601ElNTVVQUJASEhJK3R8yd4ALa1TzqHq22qa61U6patAFDZ+fpHW7alrK+7X7Xvc02K+IkFwVFnlo9+GqmvnVXdqZfXlOR++2afpT3SzdfutpFRZ5qN2YPle8T0TweSU/uF5Nah3VhYJKWpEWp7e/bK4iM38foux8NC1cG1eEKHuft7x8zEpoekF9Xz6q6NqXJ7wX5Js0a0yU1iytosKLJjVpc17PphxWlarF+4Lt3+mjj9+K0I7v/JXzSyVFVC9Qx8f/qwf7/dfqvb5ZXEUfvx2uowe85R9UpKZtc/TkyKMKCi26qfeMiis3N1f79u2zvD548KDS09MVGhqqmJgYtW7dWsOHD5evr69iY2O1du1azZ8/X2+88YYkKTg4WH379tXQoUMVGhqqoKAgPfvss0pMTNTdd98tSWrfvr0SEhL02GOPadKkSTp+/Lj+/ve/a+DAgXYNF/NfZhsOHTokk8mk9PT08u6Ky1mzZo1MJpPOnj1b3l1xa76VL2nvsTBN/rzlVcuzToXotaUt9Og/u+upGV107GygpvZdrhD/Xy11KnuateqnWlr07dX/KvQwmfXGE/9RJc8i9ZvRRWM//rM6NsnUU/d8Xyb3BJTYvjlAnXr/V/9ctlcpH+1X0SXpb4/cpvwLl7+6Zo6upi2pwfr7O4f02uJ9OnOissb2rWEp37fdTyG3XFLyWz9r1urdeuS5E3p/QpQ+f+8WS52d3/lr8uAYdXj4tGat2a2X3zmkzHQ//XN49M28XdjB0cUUJYc9tm7dqsaNG6tx48aSive1a9y4sWUPuo8++kjNmjVTjx49lJCQoIkTJ2r8+PHq37+/pY0pU6bo/vvvV7du3dSqVStFRkZq8eLFlnJPT08tW7ZMnp6eSkxMVM+ePfX4449r7NixdvWVzJ0N0dHROnbsmG655ZbrV3YDa9asUdu2bfXLL79csZoHFdPmPTHavCfmmuVfbatj9frNZf+nzs12q3bkaW3dX12SNPvrZpKkjk12X7WN5nUOq2b4L3p2zv06k+unvcekd1KbadC932r21011qcjTSXcDWJvw4QGr1y/8M0t/rV9fe7f7qv7decrL8dCX/w7ViOk/q1GLXEnS0Dey9GTreGWk+Sm+yQUlPXLGqo1bYwuUsdVPG/8TrM59irN3u9L8FBFdoC7/y+ZFxhSoY8/T+vjt8Jtwl7gRZplkdnDOnb3Xt2nTRoZx7bHcyMhIvf/++zbb8PHx0fTp06+5EbIkxcbGasWKFXb17ffI3Nng6empyMhIVark2jGwPRsfwn1V8ixSl7t26fyvXtp7LKzU19WPPaH9x0N1JtfPcm7LnmgF+BSoVsQvZdFV4Krycor/kAgMKR4q3bvdT5cKPdS4Za6lTkydiwqvVqCMNP9rt3Pe09KGJCU0uaBTRyvru1WBMgzpl1OVtH55iJr9OaeM7gSOKo8nVLiSP3xwt3LlSrVo0UIhISEKCwvT/fffr/3790uyf1h26dKlqlOnjnx8fNS2bVvNmzfviqHJDRs2qGXLlvL19VV0dLQGDx6svLw8S3mNGjU0YcIE9enTR4GBgYqJidGsWbOs3ic7O1vdu3dXSEiIQkND1blzZx06dMhS3rt3b3Xp0kXjx49XVFSU4uLiJEkffPCBmjZtqsDAQEVGRurRRx+1TNo8dOiQ2rZtK0mqUqWKTCaTevfuLUkym81KSUlRzZo15evrq4YNG+rTTz+16tOKFSt0++23y9fXV23btrXqD8rXn+r+rNVj5mj9uNl6uMV2Pfvu/Tp3wbfU14cFXNCZXOv6Ja/DAi44ta/AtZjN0sxXqumOZrmqUTdfknTmZCVV9jIrINh6XlxI1UKdOXn1P8p3fu+ntUur6L4epy3n7rgrT8lv/awJ/WuoY2xDPdywnvwDizRowuGyuyGgDP3hg7u8vDwNHTpUW7du1apVq+Th4aEHH3zQsrqltA4ePKiHHnpIXbp00bZt2/T000/r5Zdftqqzf/9+dejQQd26ddP27du1cOFCbdiwQYMGDbKq9/rrr6tp06b68ccfNWDAAD3zzDPKzMyUVLwiJykpSYGBgVq/fr02btyogIAAdejQwSpDt2rVKmVmZio1NVXLli2zXDtu3Dht27ZNS5Ys0aFDhywBXHR0tBYtWiSpePXOsWPH9Oabb0qSUlJSNH/+fM2cOVM7d+7UkCFD1LNnT61du1ZScbDZtWtXderUSenp6erXr59GjBhx3Z/ZxYsXr9gZHM6Xtj9Kj039f3pyxoPasidGEx5NVZXfzLkDXMFbf6uun3f76qUZP99wG4d2+2jME7XUc+hxNWlz3nL+5z3emjGqunoMOa63VmZq/If7deKwl6YmM+euoiqPOXeuxLXHG52gW7duVq/fe+89Va1aVbt27VJAQECp23nnnXcUFxenyZMnS5Li4uK0Y8cOjR8/3lInJSVFPXr00PPPPy9JqlOnjqZOnarWrVtrxowZ8vHxkSTdd999GjBggCQpOTlZU6ZM0erVqxUXF6eFCxfKbDZrzpw5MpmKU8rvv/++QkJCtGbNGstjTvz9/TVnzhx5eXlZ3r9Pn8urIGvVqqWpU6eqWbNmys3NVUBAgEJDQyVJ4eHhljl3Fy9e1IQJE/T1119blmrXqlVLGzZs0DvvvGPp+2233abXX3/dcu8//fST/vGPf9j8maWkpGjMmDGl/hnjxuQXVtbh08E6fDpYO7Ij9OmwD/VAswzNW3Nnqa4/neunhOiTVudCA361lAFl7a2/VdO3qUF6/bN9qhpVaDkfGn5JhQUeyj3naZW9O3uqskLDL1m18fMebyV3v0339vyvHn3+hFXZwmkRuqNZnv7fgFOSpFoJ+fLxPawXHqyjXsnHFBZh3RbKn1mXHx/mSBvuyn3D1lLau3evHnnkEdWqVUtBQUGqUaOGJCkrK8uudjIzM9WsWTOrc3fddZfV623btmnu3LkKCAiwHElJSTKbzTp48KClXoMGDSz/NplMioyMtAyfbtu2Tfv27VNgYKCljdDQUOXn51uGkyWpfv36VoGdVPxcu06dOikmJkaBgYFq3br1de913759unDhgu655x6rfs+fP9/yfhkZGWrevLnVdSWBoC0vvfSSzp07Zzmys7Ovew0cZzJJlSuVfnuHn36O0G2RZ6yyfc3rHFZuvpcOnqhSFl0EJEmGURzYbVoZrEmf7FNkjPX84ToNLqhSZbN+3HD5D/Hsfd46ecRL8U0uT3c5lOmjFx+qrXv+3xk9MeLKRzjl/+ohk8l6oryH5/9eO3EvNOBm+cNn7jp16qTY2FjNnj1bUVFRMpvNqlevXpksQsjNzdXTTz+twYMHX1EWE3N5xWPlypWtykwmk2WYODc3V02aNNGCBQuuaKNq1aqWf/v7W08mzsvLU1JSkpKSkrRgwQJVrVpVWVlZSkpKsnmvubnFE5WXL1+uatWqWZXd6CNafnu9o2380fl6Fap62DnL66jQHNW59b/KueCtcxd89MSff9D6XTX03/N+CvHP10OJO1Q1KE+rtt9muSYi+LyC/C4qMiRXHh6G6txavGLw8Olg/VpQWd/ura6DJ6to9F9X6a3/3K3QgF/1dPvv9OnmO1TISlmUobf+Vl2rP6ui0e8fkG+A2TKPzj+wSN6+hvyDzEp65Ixmja6mwJAi+QcWafrL1RXfJE/xTYrngx7a7aMX/99tatrmvLo+fcrShoenoZCw4j9y7r4nR/8cHq0v5uWqaZvzOnOisma+Uk1xjfMUFknWriIynLBa1nDjzN0fOrg7ffq0MjMzNXv2bLVsWbxP2IYNG26orbi4uCuWLn//vfU+YHfeead27dql2rVr31iH/9fGwoULFR4ebtfjUnbv3q3Tp09r4sSJio4unkeydetWqzolmb6iot+sIktIkLe3t7KysiyZvt+Lj4/X0qVLrc5t2bKl1H3DjYuvflIznvrC8nrI/ZslScvSbtc/Pmul2KpndV/PLxXin69zF3yUcThcT7/TWQdPhlquear997q/yR7L6389V7xY5plZnfTDgWoyGx56Ye69Su6yTnOeWaJfCyppxQ9xmpVqnakGnG3ZvOJtqIZ3s97S54UpWWr/1+ItTvqPPiIPk6FxT9ZQ4UWTmrY5r0EplxdCrF8WonOnK2vVolCtWnT59z6ieoHmf7dLktT+r2f0a66Hlr5/i2aPqSb/4CI1+tN59X35WFnfIm5QyVMmHG3DXf2hg7sqVaooLCxMs2bN0q233qqsrKxSLQS4mqefflpvvPGGkpOT1bdvX6Wnp2vu3LmSZJkbl5ycrLvvvluDBg1Sv3795O/vr127dik1NVVvvfVWqd6nR48emjx5sjp37qyxY8eqevXq+vnnn7V48WK9+OKLql69+lWvi4mJkZeXl6ZNm6b+/ftrx44dGjdunFWd2NhYmUwmLVu2TPfdd598fX0VGBioYcOGaciQITKbzWrRooXOnTunjRs3KigoSL169VL//v31+uuva/jw4erXr5/S0tIs946y9cOBamo+ov81y0f8K+m6bYz75M8a98mfbdY5fjZQQ+Z2tLt/gCO+PJp+3TpePoYGpRzRoJQjVy1/bNhxPTbsyqHY3+vc97/q3Pe/160HuII/9Jw7Dw8PffTRR0pLS1O9evU0ZMgQy4IIe9WsWVOffvqpFi9erAYNGmjGjBmW1bIlQ48NGjTQ2rVrtWfPHrVs2dKys3VUVFSp38fPz0/r1q1TTEyMunbtqvj4ePXt21f5+fk2M3lVq1bV3Llz9cknn1h2zn7ttdes6lSrVk1jxozRiBEjFBERYVnFO27cOI0cOVIpKSmKj49Xhw4dtHz5ctWsWfyYq5iYGC1atEhLlixRw4YNNXPmTE2YMMGunx8AAKXFalnbTIat7ZbhkPHjx2vmzJksFCilnJwcBQcHq/Ej4+Xp5VPe3QHKxLcTZ5R3F4AykXPerCq3H9C5c+fsmjZk13v873ui81d9VNnf6/oX2FCYV6DP279Xpv0tL3/oYVlne/vtt9WsWTOFhYVp48aNmjx58hV72AEAAJQl981JOln//v2ttgL57VHyUOC9e/eqc+fOSkhI0Lhx4/TCCy9o9OjR5dtxAADcTMmzZR093BWZu1IaO3ashg0bdtWyknTulClTNGXKlJvZLQAA/nBYLWsbwV0phYeHKzw8vLy7AQDAHx7BnW0MywIAALgRMncAAMClkLmzjeAOAAC4FII72xiWBQAAcCNk7gAAgEsxJIe3MnHnJzgQ3AEAAJfCsKxtDMsCAAC4ETJ3AADApZC5s43gDgAAuBSCO9sYlgUAAHAjZO4AAIBLIXNnG8EdAABwKYZhkuFgcObo9RUZwR0AAHApZpkc3ufO0esrMubcAQAAuBEydwAAwKUw5842gjsAAOBSmHNnG8OyAAAAboTMHQAAcCkMy9pGcAcAAFwKw7K2MSwLAADgRsjcAQAAl2I4YVjWnTN3BHcAAMClGJIMw/E23BXDsgAAAG6EzB0AAHApZplk4vFj10RwBwAAXAqrZW0juAMAAC7FbJhkYp+7a2LOHQAAgBshcwcAAFyKYThhtawbL5cluAMAAC6FOXe2MSwLAADgRsjcAQAAl0LmzjaCOwAA4FJYLWsbw7IAAABuhMwdAABwKayWtY3gDgAAuJTi4M7ROXdO6kwFxLAsAACAGyFzBwAAXAqrZW0juAMAAC7F+N/haBvuiuAOAAC4FDJ3tjHnDgAAwI2QuQMAAK6FcVmbCO4AAIBrccKwrBiWBQAAgCsgcwcAAFwKT6iwjeAOAAC4FFbL2sawLAAAgBshcwcAAFyLYXJ8QQSZOwAAgIqhZM6do4c91q1bp06dOikqKkomk0lLliy5ok5GRoYeeOABBQcHy9/fX82aNVNWVpalPD8/XwMHDlRYWJgCAgLUrVs3nThxwqqNrKwsdezYUX5+fgoPD9fw4cN16dIlu/pKcAcAAHAdeXl5atiwoaZPn37V8v3796tFixaqW7eu1qxZo+3bt2vkyJHy8fGx1BkyZIi++OILffLJJ1q7dq2OHj2qrl27WsqLiorUsWNHFRQUaNOmTZo3b57mzp2rUaNG2dVXhmUBAIBrKYdNjO+9917de++91yx/+eWXdd9992nSpEmWc7fddpvl3+fOndO7776rDz/8UH/+858lSe+//77i4+O1ZcsW3X333frqq6+0a9cuff3114qIiFCjRo00btw4JScna/To0fLy8ipVX0sV3C1durRUjUnSAw88UOq6AAAA9nLmatmcnByr897e3vL29rarLbPZrOXLl+vFF19UUlKSfvzxR9WsWVMvvfSSunTpIklKS0tTYWGh2rVrZ7mubt26iomJ0ebNm3X33Xdr8+bNql+/viIiIix1kpKS9Mwzz2jnzp1q3LhxqfpTquCupGPXYzKZVFRUVKq6AAAAN8xJ+9RFR0dbvX7llVc0evRou9o4efKkcnNzNXHiRL366qv6xz/+oZUrV6pr165avXq1WrdurePHj8vLy0shISFW10ZEROj48eOSpOPHj1sFdiXlJWWlVargzmw2l7pBAAAAV5Gdna2goCDLa3uzdtLlOKlz584aMmSIJKlRo0batGmTZs6cqdatWzuns6Xk0IKK/Px8Z/UDAACgVEqGZR09JCkoKMjquJHg7pZbblGlSpWUkJBgdT4+Pt6yWjYyMlIFBQU6e/asVZ0TJ04oMjLSUuf3q2dLXpfUKQ27g7uioiKNGzdO1apVU0BAgA4cOCBJGjlypN599117mwMAALCP4aTDSby8vNSsWTNlZmZand+zZ49iY2MlSU2aNFHlypW1atUqS3lmZqaysrKUmJgoSUpMTNRPP/2kkydPWuqkpqYqKCjoisDRFruDu/Hjx2vu3LmaNGmS1aqNevXqac6cOfY2BwAAUOHl5uYqPT1d6enpkqSDBw8qPT3dkpkbPny4Fi5cqNmzZ2vfvn1666239MUXX2jAgAGSpODgYPXt21dDhw7V6tWrlZaWpieeeEKJiYm6++67JUnt27dXQkKCHnvsMW3btk1ffvml/v73v2vgwIF2ZRTtDu7mz5+vWbNmqUePHvL09LScb9iwoXbv3m1vcwAAAHYyOekova1bt6px48aWFatDhw5V48aNLXvQPfjgg5o5c6YmTZqk+vXra86cOVq0aJFatGhhaWPKlCm6//771a1bN7Vq1UqRkZFavHixpdzT01PLli2Tp6enEhMT1bNnTz3++OMaO3asXX21e5+7I0eOqHbt2lecN5vNKiwstLc5AAAA+5TDPndt2rSRcZ3HWvTp00d9+vS5ZrmPj4+mT59+zY2QJSk2NlYrVqywr3O/Y3fmLiEhQevXr7/i/Kefflrq/VcAAABQNuzO3I0aNUq9evXSkSNHZDabtXjxYmVmZmr+/PlatmxZWfQRAADgsnLI3LkSuzN3nTt31hdffKGvv/5a/v7+GjVqlDIyMvTFF1/onnvuKYs+AgAAXGaYnHO4qRt6tmzLli2Vmprq7L4AAADAQTcU3EnFq0YyMjIkFc/Da9KkidM6BQAAcC2GUXw42oa7sju4O3z4sB555BFt3LjR8ny0s2fP6v/+7//00UcfqXr16s7uIwAAwGXMubPJ7jl3/fr1U2FhoTIyMnTmzBmdOXNGGRkZMpvN6tevX1n0EQAA4DLm3Nlkd+Zu7dq12rRpk+Li4izn4uLiNG3aNLVs2dKpnQMAAIB97A7uoqOjr7pZcVFRkaKiopzSKQAAgGsxGcWHo224K7uHZSdPnqxnn31WW7dutZzbunWrnnvuOb322mtO7RwAAMAVDCcdbqpUmbsqVarIZLo8Np2Xl6fmzZurUqXiyy9duqRKlSqpT58+6tKlS5l0FAAAANdXquDun//8Zxl3AwAAoJScsSDij76golevXmXdDwAAgNJhKxSbbngTY0nKz89XQUGB1bmgoCCHOgQAAIAbZ/eCiry8PA0aNEjh4eHy9/dXlSpVrA4AAIAyxYIKm+wO7l588UV98803mjFjhry9vTVnzhyNGTNGUVFRmj9/fln0EQAA4DKCO5vsHpb94osvNH/+fLVp00ZPPPGEWrZsqdq1ays2NlYLFixQjx49yqKfAAAAKAW7M3dnzpxRrVq1JBXPrztz5owkqUWLFlq3bp1zewcAAPB7PH7MJruDu1q1aungwYOSpLp16+rjjz+WVJzRCwkJcWrnAAAAfq/kCRWOHu7K7uDuiSee0LZt2yRJI0aM0PTp0+Xj46MhQ4Zo+PDhTu8gAACAFebc2WT3nLshQ4ZY/t2uXTvt3r1baWlpql27tho0aODUzgEAAMA+Du1zJ0mxsbGKjY11Rl8AAADgoFIFd1OnTi11g4MHD77hzgAAAFyPSY7PmXPf5RSlDO6mTJlSqsZMJhPBHQAAQDkqVXBXsjoWuBmC//2dKpkql3c3gDJR8+6nyrsLQJkw/5ovadTNeTNnbGXixluhODznDgAA4KZyxmpXN14ta/dWKAAAAKi4yNwBAADXQubOJoI7AADgUpzxhAmeUAEAAACXcEPB3fr169WzZ08lJibqyJEjkqQPPvhAGzZscGrnAAAArsDjx2yyO7hbtGiRkpKS5Ovrqx9//FEXL16UJJ07d04TJkxwegcBAACsENzZZHdw9+qrr2rmzJmaPXu2Kle+vBfZn/70J/3www9O7RwAAMDvlcy5c/RwV3YHd5mZmWrVqtUV54ODg3X27Fln9AkAAAA3yO7gLjIyUvv27bvi/IYNG1SrVi2ndAoAAOCaSp5Q4ejhpuwO7p588kk999xz+vbbb2UymXT06FEtWLBAw4YN0zPPPFMWfQQAALiMOXc22b3P3YgRI2Q2m/WXv/xFFy5cUKtWreTt7a1hw4bp2WefLYs+AgAAoJTsDu5MJpNefvllDR8+XPv27VNubq4SEhIUEBBQFv0DAACwwibGtt3wEyq8vLyUkJDgzL4AAABcH48fs8nu4K5t27Yyma49CfGbb75xqEMAAAC4cXYHd40aNbJ6XVhYqPT0dO3YsUO9evVyVr8AAACuzhn71JG5u2zKlClXPT969Gjl5uY63CEAAACbGJa16YaeLXs1PXv21Hvvvees5gAAAHADbnhBxe9t3rxZPj4+zmoOAADg6sjc2WR3cNe1a1er14Zh6NixY9q6datGjhzptI4BAABcDVuh2GZ3cBccHGz12sPDQ3FxcRo7dqzat2/vtI4BAADAfnYFd0VFRXriiSdUv359ValSpaz6BAAAgBtk14IKT09PtW/fXmfPni2j7gAAAFwHz5a1ye7VsvXq1dOBAwfKoi8AAADXVTLnztHDXdkd3L366qsaNmyYli1bpmPHjiknJ8fqAAAAQPkp9Zy7sWPH6oUXXtB9990nSXrggQesHkNmGIZMJpOKioqc30sAAIDfcuPMm6NKHdyNGTNG/fv31+rVq8uyPwAAALaxz51NpQ7uDKP4p9C6desy6wwAAAAcY9dWKL8dhgUAACgPbGJsm13B3e23337dAO/MmTMOdQgAAMAmhmVtsiu4GzNmzBVPqAAAAEDFYVdw9/DDDys8PLys+gIAAHBdDMvaVurgjvl2AACgQmBY1ia7V8sCAACUK4I7m0od3JnN5rLsBwAAAJzArjl3AAAA5Y05d7bZ/WxZAACAcmU46bDDunXr1KlTJ0VFRclkMmnJkiXXrNu/f3+ZTCb985//tDp/5swZ9ejRQ0FBQQoJCVHfvn2Vm5trVWf79u1q2bKlfHx8FB0drUmTJtnXURHcAQAAXFdeXp4aNmyo6dOn26z32WefacuWLYqKirqirEePHtq5c6dSU1O1bNkyrVu3Tk899ZSlPCcnR+3bt1dsbKzS0tI0efJkjR49WrNmzbKrrwzLAgAA11IOCyruvfde3XvvvTbrHDlyRM8++6y+/PJLdezY0aosIyNDK1eu1Pfff6+mTZtKkqZNm6b77rtPr732mqKiorRgwQIVFBTovffek5eXl+644w6lp6frjTfesAoCr4fMHQAAcCklc+4cPaTibNlvj4sXL95Qn8xmsx577DENHz5cd9xxxxXlmzdvVkhIiCWwk6R27drJw8ND3377raVOq1at5OXlZamTlJSkzMxM/fLLL6XuC8EdAAD4w4qOjlZwcLDlSElJuaF2/vGPf6hSpUoaPHjwVcuPHz9+xYMgKlWqpNDQUB0/ftxSJyIiwqpOyeuSOqXBsCwAAHAtThyWzc7OVlBQkOW0t7e33U2lpaXpzTff1A8//FAhHvpA5g4AALgUZw7LBgUFWR03EtytX79eJ0+eVExMjCpVqqRKlSrp559/1gsvvKAaNWpIkiIjI3Xy5Emr6y5duqQzZ84oMjLSUufEiRNWdUpel9QpDYI7AAAABzz22GPavn270tPTLUdUVJSGDx+uL7/8UpKUmJios2fPKi0tzXLdN998I7PZrObNm1vqrFu3ToWFhZY6qampiouLU5UqVUrdH4ZlAQCAaymH1bK5ubnat2+f5fXBgweVnp6u0NBQxcTEKCwszKp+5cqVFRkZqbi4OElSfHy8OnTooCeffFIzZ85UYWGhBg0apIcfftiybcqjjz6qMWPGqG/fvkpOTtaOHTv05ptvasqUKXb1leAOAAC4lnII7rZu3aq2bdtaXg8dOlSS1KtXL82dO7dUbSxYsECDBg3SX/7yF3l4eKhbt26aOnWqpTw4OFhfffWVBg4cqCZNmuiWW27RqFGj7NoGRSK4AwAALsb0v8PRNuzRpk0bGUbpI8JDhw5dcS40NFQffvihzesaNGig9evX29k7a8y5AwAAcCNk7gAAgGsph2FZV0JwBwAAXMpvtzJxpA13xbAsAACAGyFzBwAAXAvDsjYR3AEAANfjxsGZoxiWBQAAcCNk7gAAgEthQYVtBHcAAMC1MOfOJoZlAQAA3AiZOwAA4FIYlrWN4A4AALgWhmVtIrgDAAAuhcydbcy5AwAAcCNk7gAAgGthWNYmgjsAAOBaCO5sYlgWAADAjZC5AwAALoUFFbYR3AEAANfCsKxNDMsCAAC4ETJ3AADApZgMQybDsdSbo9dXZAR3AADAtTAsaxPDsgAAAG6EzB0AAHAprJa1jeAOAAC4FoZlbSK4AwAALoXMnW3MuQMAAHAjZO4AAIBrYVjWJoI7AADgUhiWtY1hWQAAADdC5g4AALgWhmVtIrgDAAAux52HVR3FsCwAAIAbIXMHAABci2EUH4624aYI7gAAgEthtaxtDMsCAAC4ETJ3AADAtbBa1iaCOwAA4FJM5uLD0TbcFcEd4MLqNc/V/xtwSnXqX1BY5CWN7lNDm1cG/6aGoceHn1CHR08rIKhIu7b6a+qI6jp60NtSIzDkkga8ekTN78mRYZY2rAjRjJFRyr/gKUmq7G3W4ImHVafBr4qpk69vvw7SmD41b/Kd4o/Kd2+OqqQel092niqdK9SRp+oor1EVS3nE/AMK3vJfq2vyEoJ1ZFDcFW2ZCs2KnrxLPocv6OeX7tDFaH9JUqXTF1Vr5LYr6mcNT1B+zQAn3xGcgsydTcy5s+HQoUMymUxKT08v7664nDVr1shkMuns2bPl3RW35uNn1oGdPnrrb9WvWt594Cl17nNK00ZU13P311H+BQ9N+PCAKntf/pM1+a0sxcbl66WHa2lUr5qq3zxXz08+bCn38DBUkO+hz9+9RT+uDyzzewJ+y1Rg1sXqfjr519hr1slLCNb+lEaW41if265a75bPslUUXPma7WQPjrNqJz/Gz+H+A+WB4M6G6OhoHTt2TPXq1SvvrtwUBGSuZ+vqIM2bdKs2WWXrShjq0u+U/v1mhDZ/GayDGb6aNDhGYRGF+r8O5yRJ0bXz1ezP5zXlhWhl/uivnd8F6O2/V1PrzmcVGlEoSbr4q6emvVRd//kwTGdOkuzHzXXhjhCdfqC6chuFXrOOUcmkomAvy2H2u/L31G/nWfllnNOprjHXbMfsX8mqHXnyFVlRlayWdfRwV/yX2gZPT09FRkaWdzccVlBQIC8vr/LuBm6yyJgChUVc0g+/ybZdOO+p3T/6Kb7JBa39vIrim+bp/FlP7d1+OUPxw/pAGWapbuML1wgagYrFd+951XrxB5n9KulCXJD+26mazAGXM3SeOYWKWHBQR5+uI7PXtQO2qJl7ZSo0qzDCR2fuuVV5Dapcsy7KGfvc2VSuf5a0adNGgwcP1osvvqjQ0FBFRkZq9OjRlvKsrCx17txZAQEBCgoKUvfu3XXixAlL+ejRo9WoUSN98MEHqlGjhoKDg/Xwww/r/PnzpXr/lStXqkWLFgoJCVFYWJjuv/9+7d+/31Ju77Ds0qVLVadOHfn4+Kht27aaN2/eFZmwDRs2qGXLlvL19VV0dLQGDx6svLw8S3mNGjU0YcIE9enTR4GBgYqJidGsWbOs3ic7O1vdu3dXSEiIQkND1blzZx06dMhS3rt3b3Xp0kXjx49XVFSU4uKK55588MEHatq0qQIDAxUZGalHH31UJ0+etNxr27ZtJUlVqlSRyWRS7969JUlms1kpKSmqWbOmfH191bBhQ3366adWfVqxYoVuv/12+fr6qm3btlb9QfkIDb8kSTp7yvpvuLOnKik0vDgrF1r1ks6eti43F5l0/uzlOkBFdiEhWMd71dLh5+rqVJdo+e7NUfXpeyTz/764DUOR8w/oXMtwXYy9+vw5s7eHTnaL1rF+tXVkwO369bZARb2zV/7bf7mJdwI4T7nnnOfNmyd/f399++23mjRpksaOHavU1FSZzWZ17txZZ86c0dq1a5WamqoDBw7or3/9q9X1+/fv15IlS7Rs2TItW7ZMa9eu1cSJE0v13nl5eRo6dKi2bt2qVatWycPDQw8++KDMZvuX0Bw8eFAPPfSQunTpom3btunpp5/Wyy+/fEVfO3TooG7dumn79u1auHChNmzYoEGDBlnVe/3119W0aVP9+OOPGjBggJ555hllZmZKkgoLC5WUlKTAwECtX79eGzduVEBAgDp06KCCggJLG6tWrVJmZqZSU1O1bNkyy7Xjxo3Ttm3btGTJEh06dMgSwEVHR2vRokWSpMzMTB07dkxvvvmmJCklJUXz58/XzJkztXPnTg0ZMkQ9e/bU2rVrJRUHm127dlWnTp2Unp6ufv36acSIEdf9mV28eFE5OTlWBwDY43zTMOU1qKKCan7Ka1RFRwfcLp+f8+S7p/i/JyFrTsjjYpHOJEVdsw1zQGWd/cutyq8ZoIs1AvTfLtE63yxMVVKP3azbgJ0YlrWt3IdlGzRooFdeeUWSVKdOHb311ltatWqVJOmnn37SwYMHFR0dLUmaP3++7rjjDn3//fdq1qyZpOKs0ty5cxUYWDz09Nhjj2nVqlUaP378dd+7W7duVq/fe+89Va1aVbt27bJ7nt0777yjuLg4TZ48WZIUFxenHTt2WPUjJSVFPXr00PPPP2+536lTp6p169aaMWOGfHx8JEn33XefBgwYIElKTk7WlClTtHr1asXFxWnhwoUym82aM2eOTCaTJOn9999XSEiI1qxZo/bt20uS/P39NWfOHKvh2D59+lj+XatWLU2dOlXNmjVTbm6uAgICFBpaPKclPDxcISEhkooDsAkTJujrr79WYmKi5doNGzbonXfesfT9tttu0+uvv265959++kn/+Mc/bP7MUlJSNGbMGLt+zii9kvlxIVUv6czJy0NUIVUvaf9O3+I6pyopJOyS1XUenoYCQ6yvAVxF4S0+uhRQSV6nLurXupJfZo58DuSqzuDvrerF/GOncpqF6USvqy+++LVmgMJ28wdnhcVqWZvKPXPXoEEDq9e33nqrTp48qYyMDEVHR1sCO0lKSEhQSEiIMjIyLOdq1KhhCex+e31p7N27V4888ohq1aqloKAg1ahRQ1LxcLC9MjMzLQFnibvuusvq9bZt2zR37lwFBARYjqSkJJnNZh08eNBS77c/E5PJpMjISMs9bdu2Tfv27VNgYKCljdDQUOXn51sNKdevX/+KeXZpaWnq1KmTYmJiFBgYqNatW1/3fvft26cLFy7onnvuser3/PnzLe+XkZGh5s2bW11XEgja8tJLL+ncuXOWIzs7+7rXoPSOZ3np9IlKatzi8jQFv4Ai1W18QRlpxXPsMrb6KzCkSLXrX7DUadQiVyYPafePrBSE66n0S4E88y7p0v9WxZ7sHqufX66nn/9WfBwZUDxN5Vjf2jr9QPQ12/E5fMHSBuBqyj1zV7my9YfHZDLZNSzqyPWdOnVSbGysZs+eraioKJnNZtWrV89qeNOZcnNz9fTTT2vw4MFXlMXEXF7BZeuecnNz1aRJEy1YsOCKNqpWrWr5t7+/v1VZXl6ekpKSlJSUpAULFqhq1arKyspSUlKSzfvNzc2VJC1fvlzVqlWzKvP29r7aJaXm7e3tcBt/dD5+RYqqefn/v8joAtW641edP+upU0e8tGROVT3y3EkdOeit41le6vXicZ0+UdmyUCJ7n4++/yZQz792WNOSq8uzsqGBrx7W2s9DdObE5d/DmDr5quRlKLBKkfz8i1Trjl8lSQf+lwEEyoopv0hep/Itryufvijv7DwV+VdSkV8lha04otzGoboUVFmVT+Wr6mfZKqzqrQvxxb/jl0Kt/xtj9r4oSSq8xVuXqhT/ARy05ZQMTw/lRxf/QROY/ouCNp3SiZ7s51hR8WxZ28o9uLuW+Ph4ZWdnKzs725K927Vrl86ePauEhASH2z99+rQyMzM1e/ZstWzZUlLxYocbFRcXpxUrVlid+/5762GAO++8U7t27VLt2rVv+H3uvPNOLVy4UOHh4QoKCir1dbt379bp06c1ceJEy89z69atVnVKMn1FRUWWcwkJCfL29lZWVpYl0/d78fHxWrp0qdW5LVu2lLpvuHG3N/xVkxddztj2H3NUkvTVwip6fUiMPp5eVT5+Zj036bACgoq083t/vdyjlgovXk7a/2NQjAaOP6KJH+//3ybGwXr779aB/Lh/HVBk9OUFFjNS90iSkqIaluXtAfLJylP0P3dbXocvKh5pOHf3LTr5cA15H7mgoC3/leevRboUXFl58cE63am6jMr2DUyF/ueIKp8pkOFhUkGkj471ra3cO6+9/QrKGatlbaqwwV27du1Uv3599ejRQ//85z916dIlDRgwQK1bt1bTpk0dbr9KlSoKCwvTrFmzdOuttyorK6tUiwCu5emnn9Ybb7yh5ORk9e3bV+np6Zo7d64kWebGJScn6+6779agQYPUr18/+fv7a9euXUpNTdVbb71Vqvfp0aOHJk+erM6dO2vs2LGqXr26fv75Zy1evFgvvviiqle/+ma2MTEx8vLy0rRp09S/f3/t2LFD48aNs6oTGxsrk8mkZcuW6b777pOvr68CAwM1bNgwDRkyRGazWS1atNC5c+e0ceNGBQUFqVevXurfv79ef/11DR8+XP369VNaWprl3lG2tm8OuE6AZdL8yZGaP/naW/qcP1tJEwdee4NYSerV3PE/qIAb8evtQdrz9l3XLD/ybF272rsU5n1Fezl3V1XO3VWvcQXgesp9zt21mEwmff7556pSpYpatWqldu3aqVatWlq4cKFT2vfw8NBHH32ktLQ01atXT0OGDLEshrgRNWvW1KeffqrFixerQYMGmjFjhmW1bMnQY4MGDbR27Vrt2bNHLVu2VOPGjTVq1ChFRV17Fdfv+fn5ad26dYqJiVHXrl0VHx+vvn37Kj8/32Ymr2rVqpo7d64++eQTJSQkaOLEiXrttdes6lSrVk1jxozRiBEjFBERYVnFO27cOI0cOVIpKSmKj49Xhw4dtHz5ctWsWTxkERMTo0WLFmnJkiVq2LChZs6cqQkTJtj18wMAoLRYLWubyTDcOC9ZzsaPH6+ZM2eyUKCUcnJyFBwcrDbqrEomJjLDPdnKQgGuzPxrvg4PHaVz587ZNW3IHiXfE4kdxqpSZR+H2rpUmK/NK8u2v+Wlwg7LuqK3335bzZo1U1hYmDZu3KjJkydfsYcdAABwDAsqbKuww7KOysrKstq64/eHvdud9O/f/5pt9e/fX1Lx1iqdO3dWQkKCxo0bpxdeeMHqiRsAAABlzW0zd1FRUTYfG2bPPDdJGjt2rIYNG3bVspJ07pQpUzRlyhS72gUAAHYyG5cfMedIG27KbYO7SpUqObTlyO+Fh4crPDzcae0BAIAbxBMqbHLbYVkAAIA/IrfN3AEAAPdkkhMWVDilJxUTwR0AAHAtPKHCJoZlAQAA3AiZOwAA4FLY5842MncAAMC1GE467LBu3Tp16tRJUVFRMplMWrJkiaWssLBQycnJql+/vvz9/RUVFaXHH39cR48etWrjzJkz6tGjh4KCghQSEqK+ffsqNzfXqs727dvVsmVL+fj4KDo6WpMmTbKvoyK4AwAAuK68vDw1bNhQ06dPv6LswoUL+uGHHzRy5Ej98MMPWrx4sTIzM/XAAw9Y1evRo4d27typ1NRULVu2TOvWrdNTTz1lKc/JyVH79u0VGxurtLQ0TZ48WaNHj9asWbPs6ivDsgAAwKWYDEMmBxdE2Hv9vffeq3vvvfeqZcHBwUpNTbU699Zbb+muu+5SVlaWYmJilJGRoZUrV+r7779X06ZNJUnTpk3Tfffdp9dee01RUVFasGCBCgoK9N5778nLy0t33HGH0tPT9cYbb1gFgddD5g4AALgWs5OOMnTu3DmZTCaFhIRIkjZv3qyQkBBLYCdJ7dq1k4eHh7799ltLnVatWsnLy8tSJykpSZmZmfrll19K/d5k7gAAgEtxZuYuJyfH6ry3t7e8vb0dajs/P1/Jycl65JFHLI8oPX78+BVPuqpUqZJCQ0N1/PhxS52aNWta1YmIiLCUValSpVTvT+YOAAD8YUVHRys4ONhypKSkONReYWGhunfvLsMwNGPGDCf10j5k7gAAgGtx4rNls7OzLdk1SQ5l7UoCu59//lnffPONVbuRkZE6efKkVf1Lly7pzJkzioyMtNQ5ceKEVZ2S1yV1SoPMHQAAcC0lT6hw9JAUFBRkddxocFcS2O3du1dff/21wsLCrMoTExN19uxZpaWlWc598803MpvNat68uaXOunXrVFhYaKmTmpqquLi4Ug/JSgR3AAAA15Wbm6v09HSlp6dLkg4ePKj09HRlZWWpsLBQDz30kLZu3aoFCxaoqKhIx48f1/Hjx1VQUCBJio+PV4cOHfTkk0/qu+++08aNGzVo0CA9/PDDioqKkiQ9+uij8vLyUt++fbVz504tXLhQb775poYOHWpXXxmWBQAALqU8nlCxdetWtW3b1vK6JODq1auXRo8eraVLl0qSGjVqZHXd6tWr1aZNG0nSggULNGjQIP3lL3+Rh4eHunXrpqlTp1rqBgcH66uvvtLAgQPVpEkT3XLLLRo1apRd26BIBHcAAMDV/GZY1aE27NCmTRsZNq6xVVYiNDRUH374oc06DRo00Pr16+3q2+8xLAsAAOBGyNwBAACXYjIXH4624a4I7gAAgGsph2FZV8KwLAAAgBshcwcAAFyLEzcxdkcEdwAAwKU489my7ojgDgAAuBbm3NnEnDsAAAA3QuYOAAC4FkOSo1uZuG/ijuAOAAC4Fubc2cawLAAAgBshcwcAAFyLIScsqHBKTyokgjsAAOBaWC1rE8OyAAAAboTMHQAAcC1mSSYntOGmCO4AAIBLYbWsbQR3AADAtTDnzibm3AEAALgRMncAAMC1kLmzieAOAAC4FoI7mxiWBQAAcCNk7gAAgGthKxSbCO4AAIBLYSsU2xiWBQAAcCNk7gAAgGthQYVNBHcAAMC1mA3J5GBwZnbf4I5hWQAAADdC5g4AALgWhmVtIrgDAAAuxgnBnQjuAAAAKgYydzYx5w4AAMCNkLkDAACuxWzI4WFVN14tS3AHAABci2EuPhxtw00xLAsAAOBGyNwBAADXwoIKmwjuAACAa2HOnU0MywIAALgRMncAAMC1MCxrE8EdAABwLYacENw5pScVEsOyAAAAboTMHQAAcC0My9pEcAcAAFyL2SzJwU2Ize67iTHBHQAAcC1k7mxizh0AAIAbIXMHAABcC5k7mwjuAACAa+EJFTYxLAsAAOBGyNwBAACXYhhmGYZjq10dvb4iI7gDAACuxTAcH1Z14zl3DMsCAAC4ETJ3AADAtRhOWFDhxpk7gjsAAOBazGbJ5OCcOTeec8ewLAAAgBshcwcAAFwLw7I2EdwBAACXYpjNMhwclmUrFAAAgIqCzJ1NzLkDAABwI2TuAACAazEbkonM3bUQ3AEAANdiGJIc3QrFfYM7hmUBAADcCJk7AADgUgyzIcPBYVnDjTN3BHcAAMC1GGY5PizrvluhMCwLAADgRsjcAQAAl8KwrG0EdwAAwLUwLGsTwR0qjJK/oi6p0OGNx4GKyvxrfnl3ASgT5vzi3+2bkRFzxvfEJRU6pzMVkMlw57wkXMrhw4cVHR1d3t0AADggOztb1atXL5O28/PzVbNmTR0/ftwp7UVGRurgwYPy8fFxSnsVBcEdKgyz2ayjR48qMDBQJpOpvLvj9nJychQdHa3s7GwFBQWVd3cAp+N3/OYyDEPnz59XVFSUPDzKbr1mfn6+CgoKnNKWl5eX2wV2EsOyqEA8PDzK7K89XFtQUBBffHBr/I7fPMHBwWX+Hj4+Pm4ZkDkTW6EAAAC4EYI7AAAAN0JwB/xBeXt765VXXpG3t3d5dwUoE/yO44+KBRUAAABuhMwdAACAGyG4AwAAcCMEd8BNcujQIZlMJqWnp5d3V1zOmjVrZDKZdPbs2fLuCsoQn5Ebx2cEv0VwB9wk0dHROnbsmOrVq1feXbkp+LKBvfiMAM5BcAfcJJ6enoqMjFSlSq69d7izdoYHfo/PCOAcBHeAE61cuVItWrRQSEiIwsLCdP/992v//v2S7B9yWrp0qerUqSMfHx+1bdtW8+bNu+Kv/A0bNqhly5by9fVVdHS0Bg8erLy8PEt5jRo1NGHCBPXp00eBgYGKiYnRrFmzrN4nOztb3bt3V0hIiEJDQ9W5c2cdOnTIUt67d2916dJF48ePV1RUlOLi4iRJH3zwgZo2barAwEBFRkbq0Ucf1cmTJy332rZtW0lSlSpVZDKZ1Lt3b0nFj5lLSUlRzZo15evrq4YNG+rTTz+16tOKFSt0++23y9fXV23btrXqD25cmzZtNHjwYL344osKDQ1VZGSkRo8ebSnPyspS586dFRAQoKCgIHXv3l0nTpywlI8ePVqNGjXSBx98oBo1aig4OFgPP/ywzp8/X6r3t/X5kPiM8BmB0xgAnObTTz81Fi1aZOzdu9f48ccfjU6dOhn169c3ioqKjIMHDxqSjB9//PG67Rw4cMCoXLmyMWzYMGP37t3Gv//9b6NatWqGJOOXX34xDMMw9u3bZ/j7+xtTpkwx9uzZY2zcuNFo3Lix0bt3b0s7sbGxRmhoqDF9+nRj7969RkpKiuHh4WHs3r3bMAzDKCgoMOLj440+ffoY27dvN3bt2mU8+uijRlxcnHHx4kXDMAyjV69eRkBAgPHYY48ZO3bsMHbs2GEYhmG8++67xooVK4z9+/cbmzdvNhITE417773XMAzDuHTpkrFo0SJDkpGZmWkcO3bMOHv2rGEYhvHqq68adevWNVauXGns37/feP/99w1vb29jzZo1hmEYRlZWluHt7W0MHTrU2L17t/Gvf/3LiIiIsLp33JjWrVsbQUFBxujRo409e/YY8+bNM0wmk/HVV18ZRUVFRqNGjYwWLVoYW7duNbZs2WI0adLEaN26teX6V155xQgICDC6du1q/PTTT8a6deuMyMhI429/+1up3t/W58MwDD4jfEbgJAR3QBk6deqUIcn46aef7PriSk5ONurVq2d17uWXX7b6j3ffvn2Np556yqrO+vXrDQ8PD+PXX381DKP4i6tnz56WcrPZbISHhxszZswwDMMwPvjgAyMuLs4wm82WOhcvXjR8fX2NL7/80jCM4i+uiIgIyxfZtXz//feGJOP8+fOGYRjG6tWrr/iyyc/PN/z8/IxNmzZZXdu3b1/jkUceMQzDMF566SUjISHhip8HX1yOa926tdGiRQurc82aNTOSk5ONr776yvD09DSysrIsZTt37jQkGd99951hGMXBnZ+fn5GTk2OpM3z4cKN58+Y31J/ffj4Mw77gjs8InxFcm2tPbAAqmL1792rUqFH69ttv9d///ldms1lS8XBXQkJCqdvJzMxUs2bNrM7dddddVq+3bdum7du3a8GCBZZzhmHIbDbr4MGDio+PlyQ1aNDAUm4ymRQZGWkZGtq2bZv27dunwMBAq7bz8/Othsvq168vLy8vqzppaWkaPXq0tm3bpl9++aVU97pv3z5duHBB99xzj9X5goICNW7cWJKUkZGh5s2bW5UnJiZetT3Y77e/D5J066236uTJk8rIyFB0dLSio6MtZQkJCQoJCVFGRobl97FGjRpWvy8l15eGrc+HvYso+IzwGcG1EdwBTtSpUyfFxsZq9uzZioqKktlsVr169cpkgnVubq6efvppDR48+IqymJgYy78rV65sVWYymSxfMrm5uWrSpInVl1+JqlWrWv7t7+9vVZaXl6ekpCQlJSVpwYIFqlq1qrKyspSUlGTzXnNzcyVJy5cvV7Vq1azKeETUzWHr96Gsr7+Znw+Jzwj+uAjuACc5ffq0MjMzNXv2bLVs2VJS8WTuGxEXF6cVK1ZYnfv++++tXt95553atWuXateufWMd/l8bCxcuVHh4uIKCgkp93e7du3X69GlNnDjRkunZunWrVZ2SLEZRUZHlXEJCgry9vZWVlaXWrVtfte34+HgtXbrU6tyWLVtK3TfcmPj4eGVnZys7O9vy/+muXbt09uxZu7LO1+LMz4fEZ4TPCGxhtSzgJFWqVFFYWJhmzZqlffv26ZtvvtHQoUNvqK2nn35au3fvVnJysvbs2aOPP/5Yc+fOlVScVZCk5ORkbdq0SYMGDVJ6err27t2rzz//XIMGDSr1+/To0UO33HKLOnfurPXr1+vgwYNas2aNBg8erMOHD1/zupiYGHl5eWnatGk6cOCAli5dqnHjxlnViY2Nlclk0rJly3Tq1Cnl5uYqMDBQw4YN05AhQzRv3jzt379fP/zwg6ZNm6Z58+ZJkvr376+9e/dq+PDhyszM1Icffmi5d5Sddu3aqX79+urRo4d++OEHfffdd3r88cfVunVrNW3a1OH2nfn5kPiM8BmBLQR3gJN4eHjoo48+UlpamurVq6chQ4Zo8uTJN9RWzZo19emnn2rx4sVq0KCBZsyYoZdfflnS5aGZBg0aaO3atdqzZ49atmypxo0ba9SoUYqKiir1+/j5+WndunWKiYlR165dFR8fr759+yo/P99mlqJq1aqaO3euPvnkEyUkJGjixIl67bXXrOpUq1ZNY8aM0YgRIxQREWH5Qh03bpxGjhyplJQUxcfHq0OHDlq+fLlq1qwpqfhLcdGiRVqyZIkaNmyomTNnasKECXb9/GA/k8mkzz//XFWqVFGrVq3Url071apVSwsXLnRK+878fEh8RviMwBaTYRhGeXcCwPWNHz9eM2fOVHZ2dnl3BaiQ+IwAxZhzB1RQb7/9tpo1a6awsDBt3LhRkydPtms4CXB3fEaAq2NYFigH/fv3V0BAwFWP/v37SyreNqJz585KSEjQuHHj9MILL1g9TQCoSLKysq75Ox0QEKCsrCy72uMzAtw4hmWBcnDy5Enl5ORctSwoKEjh4eE3uUeAYy5dumTzEVg1atSw65mxfEaAG0dwBwAA4EYYlgUAAHAjBHcAAABuhOAOAADAjRDcAQAAuBGCOwD4jd69e6tLly6W123atNHzzz9/0/uxZs0amUwmnT179pp1TCaTlixZUuo2R48erUaNGjnUr0OHDslkMik9Pd2hdgCUHYI7ABVe7969ZTKZZDKZ5OXlpdq1a2vs2LG6dOlSmb/34sWLr3gm6LWUJiADgLLGEyoAuIQOHTro/fff18WLF7VixQoNHDhQlStX1ksvvXRF3YKCAnl5eTnlfUNDQ53SDgDcLGTuALgEb29vRUZGKjY2Vs8884zatWunpUuXSro8lDp+/HhFRUUpLi5OkpSdna3u3bsrJCREoaGh6ty5s9VGu0VFRRo6dKhCQkIUFhamF198Ub/f+vP3w7IXL15UcnKyoqOj5e3trdq1a+vdd9/VoUOH1LZtW0lSlSpVZDKZ1Lt3b0mS2WxWSkqKatasKV9fXzVs2FCffvqp1fusWLFCt99+u3x9fdW2bVubGwJfS3Jysm6//Xb5+fmpVq1aGjlypAoLC6+o98477yg6Olp+fn7q3r27zp07Z1U+Z84cxcfHy8fHR3Xr1tXbb79td18AlB+COwAuydfXVwUFBZbXq1atUmZmplJTU7Vs2TIVFhYqKSlJgYGBWr9+vTZu3KiAgAB16NDBct3rr7+uuXPn6r333tOGDRt05swZffbZZzbf9/HHH9e///1vTZ06VRkZGXrnnXcUEBCg6OhoLVq0SJKUmZmpY8eO6c0335QkpaSkaP78+Zo5c6Z27typIUOGqGfPnlq7dq2k4iC0a9eu6tSpk9LT09WvXz+NGDHC7p9JYGCg5s6dq127dunNN9/U7NmzNWXKFKs6+/bt08cff6wvvvhCK1eu1I8//qgBAwZYyhcsWKBRo0Zp/PjxysjI0IQJEzRy5EjNmzfP7v4AKCcGAFRwvXr1Mjp37mwYhmGYzWYjNTXV8Pb2NoYNG2Ypj4iIMC5evGi55oMPPjDi4uIMs9lsOXfx4kXD19fX+PLLLw3DMIxbb73VmDRpkqW8sLDQqF69uuW9DMMwWrdubTz33HOGYRhGZmamIclITU29aj9Xr15tSDJ++eUXy7n8/HzDz8/P2LRpk1Xdvn37Go888ohhGIbx0ksvGQkJCVblycnJV7T1e5KMzz777JrlkydPNpo0aWJ5/corrxienp7G4cOHLef+85//GB4eHsaxY8cMwzCM2267zfjwww+t2hk3bpyRmJhoGIZhHDx40JBk/Pjjj9d8XwDlizl3AFzCsmXLFBAQoMLCQpnNZj366KNWD4mvX7++1Ty7bdu2ad++fQoMDLRqJz8/X/v379e5c+d07NgxNW/e3FJWqVIlNW3a9Iqh2RLp6eny9PRU69atS93vffv26cKFC7rnnnuszhcUFKhx48aSpIyMDKt+SFJiYmKp36PEwoULNXXqVO3fv1+5ubm6dOmSgoKCrOrExMSoWrVqVu9jNpuVmZmpwMBA7d+/X3379tWTTz5pqXPp0iUFBwfb3R8A5YPgDoBLaNu2rWbMmCEvLy9FRUVd8RB6f39/q9e5ublq0qSJFixYcEVbVatWvaE++Pr62n1Nbm6uJGn58uVWQZVUPI/QWTZv3qwePXpozJgxSkpKUnBwsD766CO9/vrrdvd19uzZVwSbnp6eTusrgLJFcAfAJfj7+6t27dqlrn/nnXdq4cKFCg8PvyJ7VeLWW2/Vt99+q1atWkkqzlClpaXpzjvvvGr9+vXry2w2a+3atWrXrt0V5SWZw6KiIsu5hIQEeXt7Kysr65oZv/j4eMvikBJbtmy5/k3+xqZNmxQbG6uXX37Zcu7nn3++ol5WVpaOHj2qqKgoy/t4eHgoLi5OERERioqK0oEDB9SjRw+73h9AxcGCCgBuqUePHrrlllvUuXNnrV+/XgcPHtSaNWs0ePBgHT58WJL03HPPaeLEiVqyZIl2796tAQMG2NyjrkaNGurVq5f69OmjJUuWWNr8+OOPJUmxsbEymUxatmyZTp06pdzcXAUGBmrYsGEaMmSI5s2bp/379+uHH37QtGnTLIsU+vfvr71792r48OHKzMzUhx9+qLlz59p1v3Xq1FFWVpY++ugj7d+/X1OnTr3q4hAfHx/16tVL27Zt0/r16zV48GB1795dkZGRkqQxY8YoJSVFU6dO1Z49e/TTTz/p/fff1xtvvGFXfwCUH4I7AG7Jz89P69atU0xMjLp27ar4+Hj17dtX+fn5lkzeCy+8oMcee0y9evVSYmKiAgMD9eCDD9psd8aMGXrooYc0YMAA1a1bV08++aTy8vIkSdWqVdOYMWM0YsQIRUREaNCgQZKkcePGaeTIkUpJSVF8fLw6dOig5cuXq2bNmpKK58EtWrRIS5YsUcOGDTVz5kxNmDDBrvt94IEHNGTIEA0aNEiNGjXSpk2bNHLkyCvq1a5dW127dtV9992n9u3bq0GDBlZbnfTr109z5szR+++/r/r166t169aaO3eupa8AKj6Tca2ZwwAAAHA5ZO4AAADcCMEdAACAGyG4AwAAcCMEdwAAAG6E4A4AAMCNENwBAAC4EYI7AAAAN0JwBwAA4EYI7gAAANwIwR0AAIAbIbgDAABwIwR3AAAAbuT/A5AOo3Q/9aCbAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}